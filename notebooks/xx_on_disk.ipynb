{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cache_users_on_disk(data, cache_dir):\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    for iid, group in tqdm(data.groupby('installation_id')):\n",
    "        filename = os.path.join(cache_dir, iid)\n",
    "        group.reset_index(drop=True).to_feather(filename)\n",
    "    return cache_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedAlgorithm:\n",
    "    def __init__(self, extractor, meta, files_per_batch=128,\n",
    "                 pbar=True, num_workers=cpu_count()):\n",
    "        self.extractor = extractor\n",
    "        self.meta = meta\n",
    "        self.files_per_batch = files_per_batch\n",
    "        self.pbar = pbar\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "    def run(self, cache_dir, output_dir):\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        def _extract(filename):\n",
    "            df = feather.read_dataframe(filename)\n",
    "            features = self.extractor(df, self.meta)\n",
    "            return pd.DataFrame(features)\n",
    "        \n",
    "        def _save(pair):\n",
    "            dataframe, filename = pair\n",
    "            name = os.path.basename(filename)\n",
    "            output_file = os.path.join(output_dir, name)\n",
    "            dataframe = dataframe.reset_index(drop=True)\n",
    "            dataframe.to_pickle(output_file)\n",
    "            return output_file\n",
    "        \n",
    "        filenames = [os.path.join(cache_dir, fn) for fn in os.listdir(cache_dir)]\n",
    "        chunks = list(U.chunks(filenames, self.files_per_batch))\n",
    "        if self.pbar:\n",
    "            chunks = tqdm(chunks)\n",
    "        output_files = []\n",
    "        n = self.num_workers\n",
    "        for chunk in chunks:\n",
    "            datasets = U.parallel(_extract, chunk, num_workers=n)\n",
    "            saved_files = U.parallel(_save, zip(datasets, chunk), num_workers=n)\n",
    "            output_files.extend(saved_files)\n",
    "        return output_files"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
