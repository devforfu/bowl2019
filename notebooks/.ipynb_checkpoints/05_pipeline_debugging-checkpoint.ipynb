{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cp /kaggle/input/data-bowl-2019-external-data/*.py /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "import jupytools.syspath\n",
    "def ignore(*args, **kwargs): pass\n",
    "warnings.warn = ignore\n",
    "jupytools.syspath.add('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "from functools import partial\n",
    "from multiprocessing import cpu_count\n",
    "from os.path import join\n",
    "\n",
    "import feather\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import bundle\n",
    "import utils as U\n",
    "from dataset import load, load_sample, Subset, to_accuracy_group\n",
    "from metric import qwk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending The Dataset\n",
    "\n",
    "The original datasets are processed as the whole to extend them with additional columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CYCLIC_FEATURES = ('Year', 'Month', 'Week', 'Dayofweek', 'Hour', 'Minute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature_combinations(data, pairs):\n",
    "    for c1, c2 in pairs:\n",
    "        assert c1 in data.columns, f'Column not found: {c1}'\n",
    "        assert c2 in data.columns, f'Column not found: {c2}'\n",
    "        data[f'{c1}_{c2}'] = data[c1].astype(str).str.cat(data[c2].astype(str), '_')\n",
    "    return data\n",
    "\n",
    "def add_datetime(data, column, prefix=None, with_time=True):\n",
    "    data[column] = pd.to_datetime(data[column])\n",
    "    prefix = U.default(prefix, re.sub('[Dd]ate$', '', column))\n",
    "    attrs = ('Year', 'Month', 'Week', 'Day', 'Dayofweek')\n",
    "    if with_time:\n",
    "        attrs += ('Hour', 'Minute')\n",
    "    for attr in attrs:\n",
    "        data[f'{prefix}_{attr}'] = getattr(data[column].dt, attr.lower())\n",
    "    return data\n",
    "\n",
    "def add_cyclical(data, prefix, features=CYCLIC_FEATURES, modulo=None):\n",
    "    modulo = modulo or {}\n",
    "    for feature in features:\n",
    "        column = f'{prefix}_{feature}'\n",
    "        m = modulo.get(feature, 23.0)\n",
    "        data[f'{column}_sin'] = np.sin(2*np.pi*data[column] / m)\n",
    "        data[f'{column}_cos'] = np.cos(2*np.pi*data[column] / m)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Meta Information\n",
    "\n",
    "The meta-information is computed using public train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meta_data(dataset, *datasets):\n",
    "    datasets = [dataset] + list(datasets)\n",
    "    uniq = OrderedDict()\n",
    "    uniq['title_event_code'] = U.unique(datasets, column='title_event_code')\n",
    "    uniq['title'] = U.unique(datasets, column='title')\n",
    "    uniq['event_code'] = U.unique(datasets, column='event_code')\n",
    "    uniq['event_id'] = U.unique(datasets, column='event_id')\n",
    "    uniq['world'] = U.unique(datasets, column='world')\n",
    "    uniq['type'] = U.unique(datasets, column='type')\n",
    "    asm_datasets = [ds.query('type == \"Assessment\"') for ds in datasets]\n",
    "    uniq['assessment_titles'] = U.unique(asm_datasets, column='title')\n",
    "    win_codes = {t: 4100 for t in uniq['title']}\n",
    "    win_codes['Bird Measurer (Assessment)'] = 4110\n",
    "    meta = {'win_codes': win_codes, **uniq}\n",
    "    return U.named_tuple('Meta', **meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Features\n",
    "\n",
    "Converts the raw dataset into user-specific features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturesExtractor:\n",
    "    def __init__(self, steps):\n",
    "        self.steps = steps\n",
    "        \n",
    "    def init_steps(self, meta):\n",
    "        for step in self.steps:\n",
    "            if hasattr(step, 'init'):\n",
    "                step.init(meta)\n",
    "                \n",
    "    def __call__(self, user, meta, test=False):\n",
    "        rows = []\n",
    "        self.init_steps(meta)\n",
    "        for _, session in user.groupby('game_session', sort=False):\n",
    "            info = session_info(session, meta, test)\n",
    "            features = OrderedDict([\n",
    "                ('installation_id', info.installation_id),\n",
    "                ('game_session', info.game_session),\n",
    "                ('session_title', info.session_title)\n",
    "            ])\n",
    "            for step in self.steps:\n",
    "                extracted = step.extract(session, info, meta)\n",
    "                features.update(extracted)\n",
    "            if info.should_include:\n",
    "                rows.append(features)\n",
    "        return [rows[-1]] if test else rows\n",
    "    \n",
    "def session_info(session, meta, test):\n",
    "    \"\"\"Computes information about user's session.\"\"\"\n",
    "    assert not session.empty, 'Session cannot be empty!'\n",
    "    session_type = session['type'].iloc[0]\n",
    "    assessment = session_type == 'Assessment'\n",
    "    outcomes = attempt_outcomes(session, meta) if assessment else None\n",
    "    should_include = (\n",
    "        (assessment and test) or\n",
    "        (assessment and (len(session) > 1) and outcomes.total > 0))\n",
    "    duration = session.timestamp.iloc[-1] - session.timestamp.iloc[0]\n",
    "    return U.named_tuple(\n",
    "        name='Info', \n",
    "        installation_id=session['installation_id'].iloc[0],\n",
    "        game_session=session['game_session'].iloc[0],\n",
    "        session_title=session['title'].iloc[0],\n",
    "        session_type=session_type,\n",
    "        is_assessment=assessment,\n",
    "        should_include=should_include,\n",
    "        outcomes=outcomes,\n",
    "        duration_seconds=duration.seconds)\n",
    "\n",
    "def attempt_outcomes(session, meta):\n",
    "    \"\"\"Computes how many successful and unsuccessful attempts contains the session.\"\"\"\n",
    "    event_code = meta.win_codes.get(session.title.iloc[0], 4100)\n",
    "    total_attempts = session.query(f'event_code == {event_code}')\n",
    "    pos = total_attempts.event_data.str.contains('true').sum()\n",
    "    neg = total_attempts.event_data.str.contains('false').sum()\n",
    "    summary = dict(pos=pos, neg=neg, total=(pos + neg))\n",
    "    return U.named_tuple('Trial', **summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseFeatures:\n",
    "    def __init__(self, meta):\n",
    "        self.init(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CountingFeatures(BaseFeatures):\n",
    "    def init(self, meta):\n",
    "        self.cnt_title_event_code = U.init_dict(meta.title_event_code)\n",
    "        self.cnt_title = U.init_dict(meta.title)\n",
    "        self.cnt_event_code = U.init_dict(meta.event_code)\n",
    "        self.cnt_event_id = U.init_dict(meta.event_id)\n",
    "        self.cnt_activities = U.init_dict(meta.type)\n",
    "        self.last_activity = None\n",
    "        \n",
    "    def extract(self, session, info, meta):\n",
    "        features = OrderedDict()\n",
    "        if info.should_include:\n",
    "            counters = OrderedDict([\n",
    "                *self.cnt_title_event_code.items(),\n",
    "                *self.cnt_title.items(),\n",
    "                *self.cnt_event_code.items(),\n",
    "                *self.cnt_event_id.items(),\n",
    "                *self.cnt_activities.items()])\n",
    "            features.update([(f'cnt_{k}', v) for k, v in counters.items()])\n",
    "        self.update_counters(self.cnt_title_event_code, session, 'title_event_code')\n",
    "        self.update_counters(self.cnt_title, session, 'title')\n",
    "        self.update_counters(self.cnt_event_code, session, 'event_code')\n",
    "        self.update_counters(self.cnt_event_id, session, 'event_id')\n",
    "        if self.last_activity is None or self.last_activity != info.session_type:\n",
    "            self.cnt_activities[info.session_type] += 1\n",
    "            self.last_activity = info.session_type\n",
    "        return features\n",
    "        \n",
    "    def update_counters(self, cnt, sess, column):\n",
    "        uniq_counts = Counter(sess[column])\n",
    "        for k, v in uniq_counts.items():\n",
    "            if k in cnt:\n",
    "                cnt[k] += v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerformanceFeatures(BaseFeatures):\n",
    "    def init(self, meta):\n",
    "        self.acc_accuracy = 0\n",
    "        self.acc_accuracy_group = 0\n",
    "        self.acc_correct_attempts = 0\n",
    "        self.acc_incorrect_attempts = 0\n",
    "        self.acc_actions = 0\n",
    "        self.durations = []\n",
    "        self.accuracy_groups = U.init_dict([0, 1, 2, 3])\n",
    "        self.last_accuracy_title = U.init_dict([f'acc_{t}' for t in meta.title], -1)\n",
    "        self.n_rows = 0\n",
    "    \n",
    "    def extract(self, session, info, meta):\n",
    "        features = OrderedDict()\n",
    "        \n",
    "        if info.should_include:\n",
    "            features['acc_attempts_pos'] = self.acc_correct_attempts\n",
    "            features['acc_attempts_neg'] = self.acc_incorrect_attempts\n",
    "            self.acc_correct_attempts += info.outcomes.pos\n",
    "            self.acc_incorrect_attempts += info.outcomes.neg\n",
    "            \n",
    "            features['acc_accuracy'] = U.savediv(self.acc_accuracy, self.n_rows)\n",
    "            accuracy = U.savediv(info.outcomes.pos, info.outcomes.total)\n",
    "            self.acc_accuracy += accuracy\n",
    "            \n",
    "            features.update(self.last_accuracy_title)\n",
    "            self.last_accuracy_title[f'acc_{info.session_title}'] = accuracy\n",
    "            \n",
    "            features['accuracy_group'] = to_accuracy_group(accuracy)\n",
    "            self.accuracy_groups[features['accuracy_group']] += 1\n",
    "            \n",
    "            features['acc_accuracy_group'] = U.savediv(self.acc_accuracy_group, self.n_rows)\n",
    "            self.acc_accuracy_group += features['accuracy_group']\n",
    "\n",
    "            features['acc_actions'] = self.acc_actions\n",
    "            \n",
    "            features['duration_mean'] = np.mean(self.durations) if self.durations else 0\n",
    "            self.durations.append(info.duration_seconds)\n",
    "            \n",
    "            self.n_rows += 1\n",
    "            \n",
    "        self.acc_actions += len(session)\n",
    "        \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyclicFeatures(BaseFeatures):\n",
    "    def init(self, meta):\n",
    "        self.acc = defaultdict(list)\n",
    "    \n",
    "    def extract(self, session, info, meta):\n",
    "        features = OrderedDict()\n",
    "        if not info.should_include:\n",
    "            return features\n",
    "        for dt in CYCLIC_FEATURES:\n",
    "            for angle in ('sin', 'cos'):\n",
    "                key = f'ts_{dt}_{angle}'\n",
    "                acc = self.acc\n",
    "                features[f'{key}_mean'] = np.mean(acc[key]) if acc[key] else 0\n",
    "                features[f'{key}_std'] = np.std(acc[key]) if acc[key] else 0\n",
    "                acc[key] += session[key].tolist()\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimestampFeatures(BaseFeatures):\n",
    "    def init(self, meta):\n",
    "        self.cnt_month = U.init_dict([7, 8, 9, 10])\n",
    "        self.cnt_dayofweek = U.init_dict(range(7))\n",
    "        self.cnt_dayofmonth = U.init_dict(range(1, 32))\n",
    "        self.cnt_hour = U.init_dict(range(24))\n",
    "        self.cnt_minute = U.init_dict(range(60))\n",
    "        \n",
    "    def extract(self, session, info, meta):\n",
    "        features = OrderedDict()\n",
    "        if not info.should_include:\n",
    "            return features\n",
    "        \n",
    "        features.update(U.prefix_keys(self.cnt_month, 'month_'))\n",
    "        features.update(U.prefix_keys(self.cnt_dayofweek, 'dow_'))\n",
    "        features.update(U.prefix_keys(self.cnt_dayofmonth, 'dom_'))\n",
    "        features.update(U.prefix_keys(self.cnt_hour, 'hour_'))\n",
    "        features.update(U.prefix_keys(self.cnt_minute, 'minute_'))\n",
    "        \n",
    "        self.update_counters(self.cnt_month, session, 'ts_Month')\n",
    "        self.update_counters(self.cnt_dayofweek, session, 'ts_Dayofweek')\n",
    "        self.update_counters(self.cnt_dayofmonth, session, 'ts_Day')\n",
    "        self.update_counters(self.cnt_hour, session, 'ts_Hour')\n",
    "        self.update_counters(self.cnt_minute, session, 'ts_Minute')\n",
    "        \n",
    "        return U.prefix_keys(features, 'ts_')\n",
    "    \n",
    "    def update_counters(self, cnt, sess, column):\n",
    "        uniq_counts = Counter(sess[column])\n",
    "        for k, v in uniq_counts.items():\n",
    "            if k in cnt:\n",
    "                cnt[k] += v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Dataset In Memory\n",
    "There are two possible algorithms to prepare the data before training:\n",
    "1. store every user subset on disk and process it from there,\n",
    "2. keep the whole dataset in memory and process without dumping on disk (local training).\n",
    "\n",
    "The first approach is more difficult, and requires extra steps between pipeline stages. Therefore, we go with the second one and hope that the data fits into memory on kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InMemoryAlgorithm:\n",
    "    def __init__(self, extractor, meta, pbar=True, num_workers=cpu_count()):\n",
    "        self.extractor = extractor\n",
    "        self.meta = meta\n",
    "        self.pbar = pbar\n",
    "        self.num_workers = num_workers\n",
    "    \n",
    "    def run(self, dataset, test=False):\n",
    "        mode = 'test' if test else 'train'\n",
    "        U.log(f'Running algorithm in {mode} mode.')\n",
    "        \n",
    "        def _extract(user):\n",
    "            return pd.DataFrame(self.extractor(user, self.meta, test))\n",
    "        \n",
    "        grouped = dataset.groupby('installation_id', sort=False)\n",
    "        users = (g for _, g in grouped)\n",
    "        if self.pbar:\n",
    "            users = tqdm(users, total= grouped.ngroups)\n",
    "        datasets = U.parallel(_extract, users, num_workers=self.num_workers)\n",
    "        dataset = pd.concat(datasets, axis=0)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(dataset, columns, encoders=None):\n",
    "    def make_encoder(mapping):\n",
    "        return lambda x: mapping.get(x, -1)\n",
    "    encoders = encoders or {}\n",
    "    for column in columns:\n",
    "        if column in encoders:\n",
    "            dataset[column] = dataset[column].map(make_encoder(encoders[column]))\n",
    "        else:\n",
    "            encoded, labels = pd.factorize(dataset[column])\n",
    "            encoder = OrderedDict([(x, i) for i, x in enumerate(labels)])\n",
    "            encoders[column] = encoder\n",
    "            dataset[column] = encoded\n",
    "    return dataset, encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing Features\n",
    "Some features can be added only when user-wise features are created and represented as data frame. This features are created in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_user_wise_features(dataset, meta, pbar=True):\n",
    "    def transform(group_obj, key, agg): \n",
    "        return group_obj[key].transform(agg)\n",
    "    \n",
    "    events = [f'cnt_{code}' for code in meta.event_code]\n",
    "    grouped = dataset.groupby('installation_id')\n",
    "    dataset['user_session_cnt'] = transform(grouped, 'cnt_Clip', 'count')\n",
    "    dataset['user_duration_mean'] = transform(grouped, 'duration_mean', 'mean')\n",
    "    dataset['user_title_nunique'] = transform(grouped, 'session_title', 'nunique')\n",
    "    dataset['user_events_sum'] = dataset[events].sum(axis=1)\n",
    "    dataset['user_events_mean'] = transform(grouped, 'user_events_sum', 'mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Relevant Features Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelection:\n",
    "    def __init__(self, rules, ignore_cols=None):\n",
    "        self.rules = rules\n",
    "        self.ignore_cols = ignore_cols or []\n",
    "        self.selected = None\n",
    "    def select(self, dataset):\n",
    "        relevant = {}\n",
    "        total = len(dataset.columns)\n",
    "        if self.ignore_cols:\n",
    "            U.log(f'Excluding from consideration: {self.ignore_cols}')\n",
    "            dataset = dataset.drop(columns=self.ignore_cols)\n",
    "        for name, rule in self.rules:\n",
    "            U.log(f'Applying feature selection rule: {name}')\n",
    "            features = rule(dataset)\n",
    "            relevant[name] = set(features)\n",
    "            U.log(f'Selected features: {len(features)} of {total}')\n",
    "        U.log(f'Keeping only features, selected by every rule.')\n",
    "        features = set.intersection(*relevant.values())\n",
    "        U.log(f'Final number of features changed from {total} to {len(features)}')\n",
    "        return sorted(list(features))\n",
    "        \n",
    "def non_zero_rows_and_cols(dataset):\n",
    "    def nonzero(x): return not np.allclose(x, 0)\n",
    "    nonzero_rows = dataset.sum(axis=1).map(nonzero)\n",
    "    nonzero_cols = dataset.sum(axis=0).map(nonzero)\n",
    "    features = dataset.loc[nonzero_rows, nonzero_cols].columns.tolist()\n",
    "    return features\n",
    "\n",
    "def non_correlated_cols(dataset, threshold=0.995):\n",
    "    from itertools import combinations\n",
    "    correlated = set()\n",
    "    columns = dataset.columns\n",
    "    pairs = combinations(columns, 2)\n",
    "    n_pairs = len(columns)*(len(columns) - 1)//2\n",
    "    for a, b in tqdm(pairs, total=n_pairs):\n",
    "        if a in correlated: continue\n",
    "        if b in correlated: continue\n",
    "        c = np.corrcoef(dataset[a], dataset[b])[0][1]\n",
    "        if c > threshold:\n",
    "            correlated.add(b)\n",
    "    return [c for c in columns if c not in correlated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Into Prepared Pipeline\n",
    "Gathering all created functions into data preparing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train and test.\n",
      "(11341042, 11) (17690, 7) (386, 3) (1156414, 11) "
     ]
    }
   ],
   "source": [
    "sample = False\n",
    "if U.on_kaggle():\n",
    "    U.log('Loading test set only.')\n",
    "    tst_data = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\n",
    "else:\n",
    "    if sample:\n",
    "        U.log('Warning: loading train and test data sample.')\n",
    "        trn_data, _, _ = load_sample(Subset.Train, 500_000)\n",
    "        [tst_data] = load_sample(Subset.Test, 500_000)\n",
    "    else:\n",
    "        U.log('Loading train and test.')\n",
    "        trn_data, trn_spec, trn_targ = load(Subset.Train)\n",
    "        [tst_data] = load(Subset.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming train and test data.\n",
      "(11341042, 31) (1156414, 31)\n"
     ]
    }
   ],
   "source": [
    "transform = U.combine(\n",
    "    partial(add_feature_combinations, pairs=[('title', 'event_code')]),\n",
    "    partial(add_datetime, column='timestamp', prefix='ts'),\n",
    "    partial(add_cyclical, prefix='ts'))\n",
    "\n",
    "if U.on_kaggle():\n",
    "    U.log('Transforming test data only.')\n",
    "    X_tst = transform(tst_data.copy())\n",
    "    U.log(X_tst.shape)\n",
    "else:\n",
    "    U.log('Transforming train and test data.')\n",
    "    X_tst = transform(tst_data.copy())\n",
    "    X_trn = transform(trn_data.copy())\n",
    "    U.log(X_trn.shape, X_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing meta using train and test datasets.\n",
      "Saving computed meta on disk.\n"
     ]
    }
   ],
   "source": [
    "if U.on_kaggle():\n",
    "    U.log('Reading pre-computed meta from disk.')\n",
    "    meta = bundle.meta()\n",
    "else:\n",
    "    U.log('Computing meta using train and test datasets.')\n",
    "    meta = compute_meta_data(X_trn, X_tst)\n",
    "    U.log('Saving computed meta on disk.')\n",
    "    bundle.save_meta(meta, 'meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = FeaturesExtractor([\n",
    "    CountingFeatures(meta),\n",
    "    PerformanceFeatures(meta),\n",
    "    CyclicFeatures(meta),\n",
    "    TimestampFeatures(meta)\n",
    "])\n",
    "algo = InMemoryAlgorithm(extractor, meta, num_workers=12)\n",
    "cat_cols = ['session_title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train and test datasets.\n",
      "Running algorithm in train mode.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a98948f021466d9ad13664cfb0eea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running algorithm in test mode.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2c666cc786b44e0b32df79d6ea346cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if U.on_kaggle():\n",
    "    U.log('Preparing test dataset.')\n",
    "    X_tst = algo.run(X_tst, test=True)\n",
    "    encoders = bundle.encoders()\n",
    "    X_tst, _ = encode(X_tst, cat_cols, encoders=encoders)\n",
    "else:\n",
    "    U.log('Preparing train and test datasets.')\n",
    "    X_trn = algo.run(X_trn)\n",
    "    X_tst = algo.run(X_tst, test=True)\n",
    "    X_trn, encoders = encode(X_trn, cat_cols)\n",
    "    X_tst, _ = encode(X_tst, cat_cols, encoders=encoders)\n",
    "    bundle.save(encoders, 'encoders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running post-processing on train and test sets.\n"
     ]
    }
   ],
   "source": [
    "if U.on_kaggle():\n",
    "    U.log('Running post-processing on test set only.')\n",
    "    add_user_wise_features(X_tst, meta)\n",
    "else:\n",
    "    U.log('Running post-processing on train and test sets.')\n",
    "    add_user_wise_features(X_trn, meta)\n",
    "    add_user_wise_features(X_tst, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deriving relevant features from train dataset.\n",
      "Excluding from consideration: ['accuracy_group', 'installation_id', 'game_session']\n",
      "Applying feature selection rule: nonzero\n",
      "Selected features: 1069 of 1086\n",
      "Applying feature selection rule: uncorr\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "378b36db0d8642fc9336c566f439dabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=585903), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Selected features: 579 of 1086\n",
      "Keeping only features, selected by every rule.\n",
      "Final number of features changed from 1086 to 565\n"
     ]
    }
   ],
   "source": [
    "selector = FeatureSelection(\n",
    "    rules=[\n",
    "        ('nonzero', non_zero_rows_and_cols),\n",
    "        ('uncorr', non_correlated_cols),\n",
    "    ],\n",
    "    ignore_cols=[\n",
    "        'accuracy_group', \n",
    "        'installation_id', \n",
    "        'game_session'\n",
    "    ]\n",
    ")\n",
    "\n",
    "if U.on_kaggle():\n",
    "    U.log('Loading relevant features list from disk.')\n",
    "    features = bundle.features()\n",
    "else:\n",
    "    U.log('Deriving relevant features from train dataset.')\n",
    "    features = selector.select(X_trn)\n",
    "    bundle.save(features, 'features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGBM:\n",
    "    def __init__(self, config):\n",
    "        self.model = lgb.LGBMRegressor(**config.get('model_params', {}))\n",
    "        self.config = config\n",
    "    def fit(self, train_data, valid_data, metric):\n",
    "        x_trn, y_trn = train_data\n",
    "        x_val, y_val = valid_data\n",
    "        params = self.config.get('fit_params', {}).copy()\n",
    "        params['eval_set'] = [(x_trn, y_trn), (x_val, y_val)]\n",
    "        params['eval_names'] = ['trn', 'val']\n",
    "        params['eval_metric'] = metric\n",
    "        params['X'] = x_trn\n",
    "        params['y'] = y_trn\n",
    "        self.model.fit(**params)\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "MODEL_CONFIG = dict(\n",
    "    lightgbm=dict(\n",
    "        model_params=dict(\n",
    "            n_estimators=2000,\n",
    "            max_depth=15,\n",
    "            metric='rmse',\n",
    "            objective='regression',\n",
    "            learning_rate=1e-2,\n",
    "        ),\n",
    "        fit_params=dict(\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=50,\n",
    "            categorical_feature='auto'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "def get_default_config(name):\n",
    "    return MODEL_CONFIG[name]\n",
    "\n",
    "def get_model_class(name):\n",
    "    if name == 'lightgbm': return LightGBM\n",
    "    raise ValueError(f'unknown model class: {name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(data, features, bounds, model='lightgbm', version='003', chunk_size=128):\n",
    "    U.log(f'Running inference on dataset of shape: {len(features)}')\n",
    "    indexes = np.arange(len(data))\n",
    "    U.log(f'Loading external models: {model} v{version}.')\n",
    "    models = bundle.models(model=model, version=version)\n",
    "    preds = {i: [] for i, _ in enumerate(models)}\n",
    "    U.log('Running models on test data...')\n",
    "    for chunk in U.chunks(indexes, chunk_size):\n",
    "        x_test = data[features].iloc[chunk]\n",
    "        for i, model in enumerate(models):\n",
    "            pred = model.predict(x_test).tolist()\n",
    "            preds[i].extend(pred)\n",
    "    U.log('Averaging ensemble predictions.')\n",
    "    avg_preds = pd.DataFrame(preds).mean(axis=1).values\n",
    "    U.log('Rounding predictions using optimal bounds.')\n",
    "    y_hat = round_regressor_predictions(avg_preds, bounds)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(predicted, filename='submission.csv'):\n",
    "    U.log('Converting predictions into submission file.')\n",
    "    if U.on_kaggle():\n",
    "        U.log('Running on Kaggle.')\n",
    "        sample = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\n",
    "    else:\n",
    "        U.log('Running locally.')\n",
    "        [sample] = load(Subset.Sample)\n",
    "    sample['accuracy_group'] = predicted.astype(int)\n",
    "    sample.to_csv(filename, index=False)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, features, reg_metric, algo='lightgbm', n_folds=5, config=None):\n",
    "    models = []\n",
    "    folds = GroupKFold(n_splits=n_folds)\n",
    "    groups = dataset['installation_id']\n",
    "    X = dataset[features].copy()\n",
    "    y = dataset['accuracy_group']\n",
    "    oof = np.zeros(X.shape[0], dtype=np.float32)\n",
    "    model_cls = get_model_class(algo)\n",
    "    \n",
    "    for i, (trn_idx, val_idx) in enumerate(folds.split(X, y, groups), 1):\n",
    "        U.log(f'Running k-fold {i} of {n_folds}')\n",
    "        x_trn, y_trn = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "        x_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        model = model_cls(config or get_default_config(algo))\n",
    "        model.fit(train_data=(x_trn, y_trn), \n",
    "                  valid_data=(x_val, y_val), \n",
    "                  metric=getattr(reg_metric, algo))\n",
    "        oof[val_idx] = model.predict(x_val)\n",
    "        models.append(model)\n",
    "        \n",
    "    return U.named_tuple('Result', models=models, oof=oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionCappa:\n",
    "    def __init__(self, bounds):\n",
    "        self.bounds = bounds\n",
    "    def lightgbm(self, y_true, y_pred):\n",
    "        y_rounded = round_regressor_predictions(y_pred, self.bounds)\n",
    "        return 'cappa', qwk(y_true, y_rounded), True\n",
    "    \n",
    "def round_regressor_predictions(preds, coefs):\n",
    "    x = preds.copy()\n",
    "    for i, (lo, hi) in enumerate(zip(coefs[:-1], coefs[1:])):\n",
    "        x[(x > lo) & (x <= hi)] = i\n",
    "    return x\n",
    "\n",
    "def optimize_rounding_bounds(X, y):\n",
    "    def _loss(coef):\n",
    "        buckets = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels=[0, 1, 2, 3])\n",
    "        return -qwk(y, buckets)\n",
    "    \n",
    "    init_coef = [0.5, 1.5, 2.5]\n",
    "    opt_coef = scipy.optimize.minimize(_loss, init_coef, method='nelder-mead')\n",
    "    optimized = opt_coef['x']\n",
    "    return [-np.inf] + optimized.tolist() + [np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with sub-optimal rounding.\n",
      "Running k-fold 1 of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrn's rmse: 1.10675\ttrn's cappa: 0.307199\tval's rmse: 1.11533\tval's cappa: 0.29644\n",
      "[100]\ttrn's rmse: 1.03456\ttrn's cappa: 0.404188\tval's rmse: 1.05019\tval's cappa: 0.383761\n",
      "[150]\ttrn's rmse: 0.994093\ttrn's cappa: 0.462091\tval's rmse: 1.01737\tval's cappa: 0.440309\n",
      "[200]\ttrn's rmse: 0.967152\ttrn's cappa: 0.487042\tval's rmse: 1.00049\tval's cappa: 0.458632\n",
      "[250]\ttrn's rmse: 0.947414\ttrn's cappa: 0.502471\tval's rmse: 0.990941\tval's cappa: 0.466239\n",
      "[300]\ttrn's rmse: 0.931462\ttrn's cappa: 0.512626\tval's rmse: 0.985019\tval's cappa: 0.468695\n",
      "[350]\ttrn's rmse: 0.917831\ttrn's cappa: 0.520616\tval's rmse: 0.980805\tval's cappa: 0.472667\n",
      "[400]\ttrn's rmse: 0.905721\ttrn's cappa: 0.529197\tval's rmse: 0.977563\tval's cappa: 0.474146\n",
      "[450]\ttrn's rmse: 0.894574\ttrn's cappa: 0.537204\tval's rmse: 0.97563\tval's cappa: 0.474936\n",
      "[500]\ttrn's rmse: 0.8845\ttrn's cappa: 0.545491\tval's rmse: 0.974117\tval's cappa: 0.477099\n",
      "[550]\ttrn's rmse: 0.87536\ttrn's cappa: 0.551513\tval's rmse: 0.973443\tval's cappa: 0.475582\n",
      "[600]\ttrn's rmse: 0.86686\ttrn's cappa: 0.557111\tval's rmse: 0.972637\tval's cappa: 0.475267\n",
      "Early stopping, best iteration is:\n",
      "[524]\ttrn's rmse: 0.879963\ttrn's cappa: 0.548799\tval's rmse: 0.973709\tval's cappa: 0.478056\n",
      "Running k-fold 2 of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrn's rmse: 1.10444\ttrn's cappa: 0.307515\tval's rmse: 1.12311\tval's cappa: 0.290251\n",
      "[100]\ttrn's rmse: 1.03122\ttrn's cappa: 0.409421\tval's rmse: 1.05996\tval's cappa: 0.380895\n",
      "[150]\ttrn's rmse: 0.989942\ttrn's cappa: 0.463098\tval's rmse: 1.02717\tval's cappa: 0.421588\n",
      "[200]\ttrn's rmse: 0.963392\ttrn's cappa: 0.488756\tval's rmse: 1.00983\tval's cappa: 0.440583\n",
      "[250]\ttrn's rmse: 0.944236\ttrn's cappa: 0.505646\tval's rmse: 0.999951\tval's cappa: 0.448016\n",
      "[300]\ttrn's rmse: 0.928591\ttrn's cappa: 0.515224\tval's rmse: 0.993713\tval's cappa: 0.451691\n",
      "[350]\ttrn's rmse: 0.915146\ttrn's cappa: 0.523903\tval's rmse: 0.989867\tval's cappa: 0.45519\n",
      "[400]\ttrn's rmse: 0.903062\ttrn's cappa: 0.532592\tval's rmse: 0.986852\tval's cappa: 0.461334\n",
      "[450]\ttrn's rmse: 0.892094\ttrn's cappa: 0.53873\tval's rmse: 0.984698\tval's cappa: 0.463808\n",
      "[500]\ttrn's rmse: 0.88199\ttrn's cappa: 0.545182\tval's rmse: 0.983108\tval's cappa: 0.465585\n",
      "[550]\ttrn's rmse: 0.872668\ttrn's cappa: 0.552415\tval's rmse: 0.982133\tval's cappa: 0.467043\n",
      "[600]\ttrn's rmse: 0.8641\ttrn's cappa: 0.558332\tval's rmse: 0.981043\tval's cappa: 0.466457\n",
      "[650]\ttrn's rmse: 0.855662\ttrn's cappa: 0.564677\tval's rmse: 0.980514\tval's cappa: 0.467194\n",
      "[700]\ttrn's rmse: 0.84781\ttrn's cappa: 0.570113\tval's rmse: 0.980091\tval's cappa: 0.467984\n",
      "[750]\ttrn's rmse: 0.840418\ttrn's cappa: 0.575349\tval's rmse: 0.97977\tval's cappa: 0.467627\n",
      "[800]\ttrn's rmse: 0.83319\ttrn's cappa: 0.580476\tval's rmse: 0.979731\tval's cappa: 0.469779\n",
      "[850]\ttrn's rmse: 0.825897\ttrn's cappa: 0.585362\tval's rmse: 0.979282\tval's cappa: 0.469582\n",
      "[900]\ttrn's rmse: 0.819134\ttrn's cappa: 0.589288\tval's rmse: 0.979403\tval's cappa: 0.468881\n",
      "Early stopping, best iteration is:\n",
      "[816]\ttrn's rmse: 0.830838\ttrn's cappa: 0.583106\tval's rmse: 0.979585\tval's cappa: 0.471234\n",
      "Running k-fold 3 of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrn's rmse: 1.10828\ttrn's cappa: 0.303281\tval's rmse: 1.09977\tval's cappa: 0.291156\n",
      "[100]\ttrn's rmse: 1.03378\ttrn's cappa: 0.420883\tval's rmse: 1.04221\tval's cappa: 0.382005\n",
      "[150]\ttrn's rmse: 0.991599\ttrn's cappa: 0.468985\tval's rmse: 1.01477\tval's cappa: 0.410335\n",
      "[200]\ttrn's rmse: 0.964555\ttrn's cappa: 0.495404\tval's rmse: 0.999924\tval's cappa: 0.430801\n",
      "[250]\ttrn's rmse: 0.944898\ttrn's cappa: 0.510962\tval's rmse: 0.990713\tval's cappa: 0.443805\n",
      "[300]\ttrn's rmse: 0.929037\ttrn's cappa: 0.52178\tval's rmse: 0.985429\tval's cappa: 0.444016\n",
      "[350]\ttrn's rmse: 0.91575\ttrn's cappa: 0.529782\tval's rmse: 0.981375\tval's cappa: 0.445869\n",
      "[400]\ttrn's rmse: 0.903736\ttrn's cappa: 0.538172\tval's rmse: 0.979095\tval's cappa: 0.447665\n",
      "[450]\ttrn's rmse: 0.892713\ttrn's cappa: 0.544732\tval's rmse: 0.977856\tval's cappa: 0.446552\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttrn's rmse: 0.90539\ttrn's cappa: 0.536576\tval's rmse: 0.979287\tval's cappa: 0.448947\n",
      "Running k-fold 4 of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrn's rmse: 1.10097\ttrn's cappa: 0.32014\tval's rmse: 1.12744\tval's cappa: 0.289798\n",
      "[100]\ttrn's rmse: 1.0264\ttrn's cappa: 0.430274\tval's rmse: 1.06743\tval's cappa: 0.389901\n",
      "[150]\ttrn's rmse: 0.984647\ttrn's cappa: 0.466677\tval's rmse: 1.03835\tval's cappa: 0.416457\n",
      "[200]\ttrn's rmse: 0.957319\ttrn's cappa: 0.498521\tval's rmse: 1.02271\tval's cappa: 0.44158\n",
      "[250]\ttrn's rmse: 0.937644\ttrn's cappa: 0.513409\tval's rmse: 1.014\tval's cappa: 0.448421\n",
      "[300]\ttrn's rmse: 0.922077\ttrn's cappa: 0.523829\tval's rmse: 1.00854\tval's cappa: 0.451064\n",
      "[350]\ttrn's rmse: 0.908354\ttrn's cappa: 0.531285\tval's rmse: 1.00496\tval's cappa: 0.453021\n",
      "[400]\ttrn's rmse: 0.896032\ttrn's cappa: 0.540083\tval's rmse: 1.00333\tval's cappa: 0.457867\n",
      "[450]\ttrn's rmse: 0.884657\ttrn's cappa: 0.54839\tval's rmse: 1.00226\tval's cappa: 0.458948\n",
      "[500]\ttrn's rmse: 0.874672\ttrn's cappa: 0.554339\tval's rmse: 1.00161\tval's cappa: 0.460607\n",
      "[550]\ttrn's rmse: 0.865344\ttrn's cappa: 0.56008\tval's rmse: 1.00105\tval's cappa: 0.46094\n",
      "[600]\ttrn's rmse: 0.857047\ttrn's cappa: 0.565351\tval's rmse: 1.00079\tval's cappa: 0.455746\n",
      "Early stopping, best iteration is:\n",
      "[540]\ttrn's rmse: 0.867213\ttrn's cappa: 0.559763\tval's rmse: 1.00107\tval's cappa: 0.461271\n",
      "Running k-fold 5 of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrn's rmse: 1.10166\ttrn's cappa: 0.308456\tval's rmse: 1.13091\tval's cappa: 0.27416\n",
      "[100]\ttrn's rmse: 1.02633\ttrn's cappa: 0.41041\tval's rmse: 1.07343\tval's cappa: 0.351446\n",
      "[150]\ttrn's rmse: 0.983354\ttrn's cappa: 0.473332\tval's rmse: 1.0456\tval's cappa: 0.412569\n",
      "[200]\ttrn's rmse: 0.956103\ttrn's cappa: 0.496595\tval's rmse: 1.03126\tval's cappa: 0.429037\n",
      "[250]\ttrn's rmse: 0.936564\ttrn's cappa: 0.51247\tval's rmse: 1.02349\tval's cappa: 0.436261\n",
      "[300]\ttrn's rmse: 0.920657\ttrn's cappa: 0.522291\tval's rmse: 1.01877\tval's cappa: 0.441361\n",
      "[350]\ttrn's rmse: 0.907131\ttrn's cappa: 0.53115\tval's rmse: 1.01602\tval's cappa: 0.444685\n",
      "[400]\ttrn's rmse: 0.894666\ttrn's cappa: 0.537287\tval's rmse: 1.01401\tval's cappa: 0.446864\n",
      "[450]\ttrn's rmse: 0.883227\ttrn's cappa: 0.54633\tval's rmse: 1.01278\tval's cappa: 0.448974\n",
      "[500]\ttrn's rmse: 0.87311\ttrn's cappa: 0.551578\tval's rmse: 1.01216\tval's cappa: 0.447065\n",
      "[550]\ttrn's rmse: 0.863838\ttrn's cappa: 0.557928\tval's rmse: 1.01176\tval's cappa: 0.451683\n",
      "[600]\ttrn's rmse: 0.855326\ttrn's cappa: 0.564795\tval's rmse: 1.01123\tval's cappa: 0.451747\n",
      "[650]\ttrn's rmse: 0.847035\ttrn's cappa: 0.570271\tval's rmse: 1.01086\tval's cappa: 0.45085\n",
      "[700]\ttrn's rmse: 0.839338\ttrn's cappa: 0.574643\tval's rmse: 1.01087\tval's cappa: 0.452807\n",
      "Early stopping, best iteration is:\n",
      "[635]\ttrn's rmse: 0.849499\ttrn's cappa: 0.568237\tval's rmse: 1.01076\tval's cappa: 0.451783\n",
      "Using predictions to find optimal rounding boundaries.\n",
      "Optimal values: [-inf, 0.5758694477650677, 1.576743676549797, 2.1624741850960385, inf]\n",
      "Using optimal boundaries to train a new ensemble of models.\n",
      "Running k-fold 1 of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrn's rmse: 1.10675\ttrn's cappa: 0.366974\tval's rmse: 1.11533\tval's cappa: 0.346042\n",
      "[100]\ttrn's rmse: 1.03456\ttrn's cappa: 0.507618\tval's rmse: 1.05019\tval's cappa: 0.485498\n",
      "[150]\ttrn's rmse: 0.994093\ttrn's cappa: 0.534401\tval's rmse: 1.01737\tval's cappa: 0.516309\n",
      "[200]\ttrn's rmse: 0.967152\ttrn's cappa: 0.577038\tval's rmse: 1.00049\tval's cappa: 0.545544\n",
      "[250]\ttrn's rmse: 0.947414\ttrn's cappa: 0.603454\tval's rmse: 0.990941\tval's cappa: 0.56713\n",
      "[300]\ttrn's rmse: 0.931462\ttrn's cappa: 0.625992\tval's rmse: 0.985019\tval's cappa: 0.570352\n",
      "[350]\ttrn's rmse: 0.917831\ttrn's cappa: 0.63978\tval's rmse: 0.980805\tval's cappa: 0.572107\n",
      "[400]\ttrn's rmse: 0.905721\ttrn's cappa: 0.652359\tval's rmse: 0.977563\tval's cappa: 0.57772\n",
      "[450]\ttrn's rmse: 0.894574\ttrn's cappa: 0.660955\tval's rmse: 0.97563\tval's cappa: 0.581102\n",
      "[500]\ttrn's rmse: 0.8845\ttrn's cappa: 0.669559\tval's rmse: 0.974117\tval's cappa: 0.583434\n",
      "[550]\ttrn's rmse: 0.87536\ttrn's cappa: 0.67703\tval's rmse: 0.973443\tval's cappa: 0.584693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600]\ttrn's rmse: 0.86686\ttrn's cappa: 0.684378\tval's rmse: 0.972637\tval's cappa: 0.587725\n",
      "[650]\ttrn's rmse: 0.858526\ttrn's cappa: 0.692209\tval's rmse: 0.971854\tval's cappa: 0.589448\n",
      "[700]\ttrn's rmse: 0.850752\ttrn's cappa: 0.6992\tval's rmse: 0.971057\tval's cappa: 0.589333\n",
      "[750]\ttrn's rmse: 0.843025\ttrn's cappa: 0.705932\tval's rmse: 0.970881\tval's cappa: 0.589112\n",
      "[800]\ttrn's rmse: 0.835584\ttrn's cappa: 0.711481\tval's rmse: 0.970848\tval's cappa: 0.588327\n",
      "Early stopping, best iteration is:\n",
      "[728]\ttrn's rmse: 0.846415\ttrn's cappa: 0.703127\tval's rmse: 0.971121\tval's cappa: 0.590911\n",
      "Running k-fold 2 of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrn's rmse: 1.10444\ttrn's cappa: 0.384527\tval's rmse: 1.12311\tval's cappa: 0.355945\n",
      "[100]\ttrn's rmse: 1.03122\ttrn's cappa: 0.512052\tval's rmse: 1.05996\tval's cappa: 0.474951\n",
      "[150]\ttrn's rmse: 0.989942\ttrn's cappa: 0.539443\tval's rmse: 1.02717\tval's cappa: 0.495005\n",
      "[200]\ttrn's rmse: 0.963392\ttrn's cappa: 0.57251\tval's rmse: 1.00983\tval's cappa: 0.522121\n",
      "[250]\ttrn's rmse: 0.944236\ttrn's cappa: 0.605973\tval's rmse: 0.999951\tval's cappa: 0.549865\n",
      "[300]\ttrn's rmse: 0.928591\ttrn's cappa: 0.626241\tval's rmse: 0.993713\tval's cappa: 0.564408\n",
      "[350]\ttrn's rmse: 0.915146\ttrn's cappa: 0.642413\tval's rmse: 0.989867\tval's cappa: 0.568983\n",
      "[400]\ttrn's rmse: 0.903062\ttrn's cappa: 0.653393\tval's rmse: 0.986852\tval's cappa: 0.572566\n",
      "[450]\ttrn's rmse: 0.892094\ttrn's cappa: 0.665182\tval's rmse: 0.984698\tval's cappa: 0.575232\n",
      "[500]\ttrn's rmse: 0.88199\ttrn's cappa: 0.673828\tval's rmse: 0.983108\tval's cappa: 0.579439\n",
      "[550]\ttrn's rmse: 0.872668\ttrn's cappa: 0.681998\tval's rmse: 0.982133\tval's cappa: 0.579695\n",
      "[600]\ttrn's rmse: 0.8641\ttrn's cappa: 0.690216\tval's rmse: 0.981043\tval's cappa: 0.582445\n",
      "[650]\ttrn's rmse: 0.855662\ttrn's cappa: 0.697779\tval's rmse: 0.980514\tval's cappa: 0.583863\n",
      "[700]\ttrn's rmse: 0.84781\ttrn's cappa: 0.704197\tval's rmse: 0.980091\tval's cappa: 0.584098\n",
      "Early stopping, best iteration is:\n",
      "[632]\ttrn's rmse: 0.858697\ttrn's cappa: 0.695113\tval's rmse: 0.980868\tval's cappa: 0.585388\n",
      "Running k-fold 3 of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrn's rmse: 1.10828\ttrn's cappa: 0.356692\tval's rmse: 1.09977\tval's cappa: 0.314804\n",
      "[100]\ttrn's rmse: 1.03378\ttrn's cappa: 0.512571\tval's rmse: 1.04221\tval's cappa: 0.474468\n",
      "[150]\ttrn's rmse: 0.991599\ttrn's cappa: 0.538356\tval's rmse: 1.01477\tval's cappa: 0.492781\n",
      "[200]\ttrn's rmse: 0.964555\ttrn's cappa: 0.585969\tval's rmse: 0.999924\tval's cappa: 0.523225\n",
      "[250]\ttrn's rmse: 0.944898\ttrn's cappa: 0.61297\tval's rmse: 0.990713\tval's cappa: 0.544098\n",
      "[300]\ttrn's rmse: 0.929037\ttrn's cappa: 0.631027\tval's rmse: 0.985429\tval's cappa: 0.552049\n",
      "[350]\ttrn's rmse: 0.91575\ttrn's cappa: 0.645653\tval's rmse: 0.981375\tval's cappa: 0.554852\n",
      "[400]\ttrn's rmse: 0.903736\ttrn's cappa: 0.656883\tval's rmse: 0.979095\tval's cappa: 0.559871\n",
      "[450]\ttrn's rmse: 0.892713\ttrn's cappa: 0.66651\tval's rmse: 0.977856\tval's cappa: 0.562239\n",
      "[500]\ttrn's rmse: 0.882602\ttrn's cappa: 0.674868\tval's rmse: 0.976957\tval's cappa: 0.563734\n",
      "[550]\ttrn's rmse: 0.873442\ttrn's cappa: 0.684157\tval's rmse: 0.976042\tval's cappa: 0.565092\n",
      "[600]\ttrn's rmse: 0.865263\ttrn's cappa: 0.694126\tval's rmse: 0.97554\tval's cappa: 0.565645\n",
      "[650]\ttrn's rmse: 0.85754\ttrn's cappa: 0.700157\tval's rmse: 0.975334\tval's cappa: 0.565558\n",
      "[700]\ttrn's rmse: 0.849221\ttrn's cappa: 0.707017\tval's rmse: 0.975074\tval's cappa: 0.569414\n",
      "[750]\ttrn's rmse: 0.84144\ttrn's cappa: 0.713226\tval's rmse: 0.975066\tval's cappa: 0.568425\n",
      "Early stopping, best iteration is:\n",
      "[690]\ttrn's rmse: 0.85086\ttrn's cappa: 0.705443\tval's rmse: 0.975069\tval's cappa: 0.570472\n",
      "Running k-fold 4 of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrn's rmse: 1.10097\ttrn's cappa: 0.380783\tval's rmse: 1.12744\tval's cappa: 0.352755\n",
      "[100]\ttrn's rmse: 1.0264\ttrn's cappa: 0.517574\tval's rmse: 1.06743\tval's cappa: 0.475256\n",
      "[150]\ttrn's rmse: 0.984647\ttrn's cappa: 0.54238\tval's rmse: 1.03835\tval's cappa: 0.486195\n",
      "[200]\ttrn's rmse: 0.957319\ttrn's cappa: 0.583494\tval's rmse: 1.02271\tval's cappa: 0.513166\n",
      "[250]\ttrn's rmse: 0.937644\ttrn's cappa: 0.615515\tval's rmse: 1.014\tval's cappa: 0.53687\n",
      "[300]\ttrn's rmse: 0.922077\ttrn's cappa: 0.635021\tval's rmse: 1.00854\tval's cappa: 0.544476\n",
      "[350]\ttrn's rmse: 0.908354\ttrn's cappa: 0.649309\tval's rmse: 1.00496\tval's cappa: 0.555301\n",
      "[400]\ttrn's rmse: 0.896032\ttrn's cappa: 0.660705\tval's rmse: 1.00333\tval's cappa: 0.555528\n",
      "[450]\ttrn's rmse: 0.884657\ttrn's cappa: 0.67016\tval's rmse: 1.00226\tval's cappa: 0.557415\n",
      "[500]\ttrn's rmse: 0.874672\ttrn's cappa: 0.678649\tval's rmse: 1.00161\tval's cappa: 0.561357\n",
      "[550]\ttrn's rmse: 0.865344\ttrn's cappa: 0.688819\tval's rmse: 1.00105\tval's cappa: 0.563386\n",
      "[600]\ttrn's rmse: 0.857047\ttrn's cappa: 0.695674\tval's rmse: 1.00079\tval's cappa: 0.563518\n",
      "Early stopping, best iteration is:\n",
      "[538]\ttrn's rmse: 0.867551\ttrn's cappa: 0.686912\tval's rmse: 1.00109\tval's cappa: 0.564688\n",
      "Running k-fold 5 of 5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttrn's rmse: 1.10166\ttrn's cappa: 0.384576\tval's rmse: 1.13091\tval's cappa: 0.332873\n",
      "[100]\ttrn's rmse: 1.02633\ttrn's cappa: 0.511579\tval's rmse: 1.07343\tval's cappa: 0.450233\n",
      "[150]\ttrn's rmse: 0.983354\ttrn's cappa: 0.543915\tval's rmse: 1.0456\tval's cappa: 0.474818\n",
      "[200]\ttrn's rmse: 0.956103\ttrn's cappa: 0.586651\tval's rmse: 1.03126\tval's cappa: 0.505832\n",
      "[250]\ttrn's rmse: 0.936564\ttrn's cappa: 0.613767\tval's rmse: 1.02349\tval's cappa: 0.517742\n",
      "[300]\ttrn's rmse: 0.920657\ttrn's cappa: 0.635156\tval's rmse: 1.01877\tval's cappa: 0.528047\n",
      "[350]\ttrn's rmse: 0.907131\ttrn's cappa: 0.651153\tval's rmse: 1.01602\tval's cappa: 0.531101\n",
      "[400]\ttrn's rmse: 0.894666\ttrn's cappa: 0.66161\tval's rmse: 1.01401\tval's cappa: 0.533318\n",
      "[450]\ttrn's rmse: 0.883227\ttrn's cappa: 0.672674\tval's rmse: 1.01278\tval's cappa: 0.538787\n",
      "[500]\ttrn's rmse: 0.87311\ttrn's cappa: 0.682458\tval's rmse: 1.01216\tval's cappa: 0.543903\n",
      "[550]\ttrn's rmse: 0.863838\ttrn's cappa: 0.690093\tval's rmse: 1.01176\tval's cappa: 0.548931\n",
      "[600]\ttrn's rmse: 0.855326\ttrn's cappa: 0.696685\tval's rmse: 1.01123\tval's cappa: 0.551852\n",
      "[650]\ttrn's rmse: 0.847035\ttrn's cappa: 0.704087\tval's rmse: 1.01086\tval's cappa: 0.552377\n",
      "[700]\ttrn's rmse: 0.839338\ttrn's cappa: 0.709676\tval's rmse: 1.01087\tval's cappa: 0.553073\n",
      "Early stopping, best iteration is:\n",
      "[635]\ttrn's rmse: 0.849499\ttrn's cappa: 0.701041\tval's rmse: 1.01076\tval's cappa: 0.552569\n",
      "Saving the final results.\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "algo = 'lightgbm'\n",
    "version = '007'\n",
    "\n",
    "if U.on_kaggle():\n",
    "    U.log('Inference on Kaggle.')\n",
    "    predicted = inference(X_tst, features, bounds=bounds, model=algo, version=version)\n",
    "    U.log('Saving predictions on disk.')\n",
    "    filename = submit(predicted)\n",
    "    submit_df = pd.read_csv(filename)\n",
    "    U.log('First 20 submission rows:')\n",
    "    display(submit_df.head(20))\n",
    "    \n",
    "else:\n",
    "    U.log('Training with sub-optimal rounding.')\n",
    "    reg_metric = RegressionCappa([-np.inf, 1., 2., 3., +np.inf])\n",
    "    result = train(X_trn, features, reg_metric, algo=algo)\n",
    "    \n",
    "    U.log('Using predictions to find optimal rounding boundaries.')\n",
    "    opt_bounds = optimize_rounding_bounds(result.oof, X_trn['accuracy_group'])\n",
    "    U.log(f'Optimal values: {opt_bounds}')\n",
    "    \n",
    "    U.log('Using optimal boundaries to train a new ensemble of models.')\n",
    "    reg_metric = RegressionCappa(opt_bounds)\n",
    "    result = train(X_trn, features, reg_metric, algo=algo)\n",
    "    \n",
    "    U.log('Saving the final results.')\n",
    "    bundle.save(result.models, f'models_{algo}_{version}')\n",
    "    bundle.save(opt_bounds, 'bounds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on dataset of shape: 565\n",
      "Loading external models: lightgbm v007.\n",
      "Running models on test data...\n",
      "Averaging ensemble predictions.\n",
      "Rounding predictions using optimal bounds.\n",
      "Converting predictions into submission file.\n",
      "Running locally.\n",
      "(1000, 2) Packaging training results into dataset.\n",
      "/tmp/bowl2019/meta.joblib --> /home/ck/data/bowl2019/external/meta.joblib\n",
      "/tmp/bowl2019/models_lightgbm_007.joblib --> /home/ck/data/bowl2019/external/models_lightgbm_007.joblib\n",
      "/tmp/bowl2019/bounds.joblib --> /home/ck/data/bowl2019/external/bounds.joblib\n",
      "/tmp/bowl2019/features.joblib --> /home/ck/data/bowl2019/external/features.joblib\n",
      "/tmp/bowl2019/encoders.joblib --> /home/ck/data/bowl2019/external/encoders.joblib\n",
      "Packaging helper scripts into dataset.\n",
      "../style.py --> /home/ck/data/bowl2019/external/style.py\n",
      "../basedir.py --> /home/ck/data/bowl2019/external/basedir.py\n",
      "../dataset.py --> /home/ck/data/bowl2019/external/dataset.py\n",
      "../extract_features.py --> /home/ck/data/bowl2019/external/extract_features.py\n",
      "../plots.py --> /home/ck/data/bowl2019/external/plots.py\n",
      "../bundle.py --> /home/ck/data/bowl2019/external/bundle.py\n",
      "../metric.py --> /home/ck/data/bowl2019/external/metric.py\n",
      "../utils.py --> /home/ck/data/bowl2019/external/utils.py\n"
     ]
    }
   ],
   "source": [
    "if not U.on_kaggle():\n",
    "    features = bundle.features()\n",
    "    bounds = bundle.bounds()\n",
    "    filename = submit(inference(X_tst, features, bounds, model=algo, version=version))\n",
    "    assert os.path.exists(filename)\n",
    "    assert pd.read_csv(filename).shape[0] == 1000\n",
    "    bundle.package(folder='/home/ck/data/bowl2019/external/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference(X_tst, features, bounds=bounds, model=algo, version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
