{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp /kaggle/input/data-bowl-2019-external-data/*.py /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2w\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "import jupytools.syspath\n",
    "def ignore(*args, **kwargs): pass\n",
    "warnings.warn = ignore\n",
    "jupytools.syspath.add('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "import selection\n",
    "import utils as U\n",
    "from metric import optimize_rounding_bounds, make_cappa_metric\n",
    "from training import EnsembleTrainer, get_default_config\n",
    "from normalize import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_train_cols = ['installation_id', 'game_session', 'accuracy_group']\n",
    "\n",
    "def read_dataset():\n",
    "    X_trn = pd.read_pickle('/tmp/X_trn.pickle')\n",
    "    X_tst = pd.read_pickle('/tmp/X_tst.pickle')\n",
    "    selector = selection.FeatureSelection(\n",
    "        rules=[('nonzero', selection.non_zero_rows_and_cols)],\n",
    "        ignore_cols=non_train_cols)\n",
    "    features = selector.select(X_trn)\n",
    "    X_trn['is_test'] = 0\n",
    "    X_tst['is_test'] = 1\n",
    "    dataset = pd.concat([X_trn, X_tst])\n",
    "    return dataset, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adversarial CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/poteman/sampling-train-data-and-use-prediction-as-feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred, t=0.5):\n",
    "    from sklearn.metrics import balanced_accuracy_score\n",
    "    y_hat = [0 if y < t else 1 for y in y_pred]\n",
    "    return balanced_accuracy_score(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adv_cv(dataset, features, algo='lightgbm', target='is_test', config=None):\n",
    "    trainer = EnsembleTrainer(\n",
    "        algo=algo, eval_metric='rmse', \n",
    "        cv_metrics={'auc': roc_auc_score, 'acc': accuracy})\n",
    "    fold = GroupKFold(n_splits=5)\n",
    "    config = config or get_default_config(algo)\n",
    "    U.set_nested(config, 'model_params.feature_fraction', 0.8)\n",
    "    U.set_nested(config, 'model_params.bagging_fraction', 0.75)\n",
    "    U.set_nested(config, 'model_params.bagging_freq', 1)\n",
    "    result = trainer.train(dataset, features, fold, target=target)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feat_imp(fi, n=200, figsize=(45, 15)):\n",
    "    f, ax = plt.subplots(1, 1, figsize=figsize, facecolor='white')\n",
    "    fi.sort_values(ascending=False).head(n).plot.bar(ax=ax)\n",
    "    ax.set_title('Most Important Features Different Between Train and Test ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train As Is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, features = read_dataset()\n",
    "result_default = adv_cv(dataset, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feat_imp(result_default.fi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE, RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding from consideration: ['installation_id', 'game_session', 'accuracy_group']\n",
      "Applying feature selection rule: nonzero\n",
      "Selected features: 1109 of 1145\n",
      "Keeping only features, selected by every rule.\n",
      "Final number of features changed from 1145 to 1109\n"
     ]
    }
   ],
   "source": [
    "dataset, features = read_dataset()\n",
    "dataset = dataset.sample(dataset.shape[0]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, features = read_dataset()\n",
    "index = np.random.permutation(dataset.index)\n",
    "dataset = dataset[index]\n",
    "fold = GroupKFold(n_splits=5)\n",
    "X = dataset[features]\n",
    "y = dataset['is_test']\n",
    "groups = dataset['installation_id']\n",
    "oof = np.zeros(X.shape[0], dtype=np.float32)\n",
    "cv = []\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(fold.split(X, y, groups), 1):\n",
    "    U.log(f'Running fold #{i}')\n",
    "    x_trn, y_trn = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    x_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    logreg = LogisticRegression(n_jobs=12)\n",
    "    logreg.fit(x_trn, y_trn)\n",
    "    probs = logreg.predict_proba(x_val)[:, 1]\n",
    "    oof[val_idx] = probs\n",
    "    cv.append(roc_auc_score(y_val, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[features]\n",
    "y = dataset['is_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "X = dataset[features]\n",
    "y = dataset['is_test']\n",
    "estimator = xgb.XGBRFClassifier(\n",
    "    gpu_id=1, tree_method='gpu_hist', max_depth=6, \n",
    "    learning_rate=1, n_estimators=250)\n",
    "selector = RFECV(estimator, cv=5, verbose=1)\n",
    "selector.fit(X, y)\n",
    "joblib.dump(selector, 'selector.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = joblib.load('selector.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(selector.ranking_) == len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluding from consideration: ['installation_id', 'game_session', 'accuracy_group']\n",
      "Applying feature selection rule: nonzero\n",
      "Selected features: 1109 of 1145\n",
      "Keeping only features, selected by every rule.\n",
      "Final number of features changed from 1145 to 1109\n",
      "Predicting with ranks above : 2\n",
      ".. running fold #1\n",
      ".. running fold #2\n",
      ".. running fold #3\n",
      ".. running fold #4\n",
      ".. running fold #5\n",
      "Predicting with ranks above : 5\n",
      ".. running fold #1\n",
      ".. running fold #2\n",
      ".. running fold #3\n",
      ".. running fold #4\n",
      ".. running fold #5\n",
      "Predicting with ranks above : 10\n",
      ".. running fold #1\n",
      ".. running fold #2\n",
      ".. running fold #3\n",
      ".. running fold #4\n",
      ".. running fold #5\n",
      "Predicting with ranks above : 20\n",
      ".. running fold #1\n",
      ".. running fold #2\n",
      ".. running fold #3\n",
      ".. running fold #4\n",
      ".. running fold #5\n",
      "Predicting with ranks above : 50\n",
      ".. running fold #1\n",
      ".. running fold #2\n",
      ".. running fold #3\n",
      ".. running fold #4\n",
      ".. running fold #5\n",
      "Predicting with ranks above : 100\n",
      ".. running fold #1\n",
      ".. running fold #2\n",
      ".. running fold #3\n",
      ".. running fold #4\n",
      ".. running fold #5\n",
      "Predicting with ranks above : 250\n",
      ".. running fold #1\n",
      ".. running fold #2\n",
      ".. running fold #3\n",
      ".. running fold #4\n",
      ".. running fold #5\n",
      "Predicting with ranks above : 500\n",
      ".. running fold #1\n",
      ".. running fold #2\n",
      ".. running fold #3\n",
      ".. running fold #4\n",
      ".. running fold #5\n",
      "Predicting with ranks above : 800\n",
      ".. running fold #1\n",
      ".. running fold #2\n",
      ".. running fold #3\n",
      ".. running fold #4\n",
      ".. running fold #5\n"
     ]
    }
   ],
   "source": [
    "dataset, features = read_dataset()\n",
    "index = np.random.permutation(dataset.index)\n",
    "dataset = dataset.loc[index]\n",
    "fold = GroupKFold(n_splits=5)\n",
    "\n",
    "X = dataset[features]\n",
    "y = dataset['is_test']\n",
    "groups = dataset['installation_id']\n",
    "\n",
    "ranks = pd.DataFrame({'feature': features, 'ranking': selector.ranking_})\n",
    "ranks = ranks.sort_values(by=['ranking'])\n",
    "threshold = (2, 5, 10, 20, 50, 100, 250, 500, 800)\n",
    "cv = defaultdict(list)\n",
    "\n",
    "for t in threshold:\n",
    "    U.log(f'Predicting with ranks above : {t}')\n",
    "    t_feat = ranks[ranks.ranking >= t].feature.tolist()\n",
    "    oof = np.zeros(X.shape[0], dtype=np.float32)\n",
    "\n",
    "    for i, (trn_idx, val_idx) in enumerate(fold.split(X, y, groups), 1):\n",
    "        U.log(f'.. running fold #{i}')\n",
    "        x_trn, y_trn = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "        x_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "        estimator = xgb.XGBRFClassifier(\n",
    "            gpu_id=1, tree_method='gpu_hist', max_depth=6, \n",
    "            learning_rate=1, n_estimators=250)\n",
    "        estimator.fit(X[t_feat], y)\n",
    "        oof[val_idx] = estimator.predict_proba(x_val[t_feat])[:, 1]\n",
    "        cv[t].append(roc_auc_score(y_val, oof[val_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bundle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/bowl2019/features.joblib'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bundle.save(ranks[ranks.ranking >= t].feature.tolist(), 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.base import clone\n",
    "\n",
    "estimator = xgb.XGBRFClassifier(gpu_id=1, tree_method='gpu_hist',\n",
    "                                max_depth=6, learning_rate=1,\n",
    "                                n_estimators=1000)\n",
    "\n",
    "folds = StratifiedKFold()\n",
    "X_sim = X[X.columns[~selector.support_]]\n",
    "cv = []\n",
    "\n",
    "for trn_idx, val_idx in folds.split(X_sim, y):\n",
    "    x_trn, y_trn = X_sim.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    x_val, y_val = X_sim.iloc[val_idx], y.iloc[val_idx]\n",
    "    trees = clone(estimator)\n",
    "    trees.fit(x_trn, y_trn)\n",
    "    probs = trees.predict_proba(x_val)[:, 1]\n",
    "    cv.append(roc_auc_score(y_val, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(X.columns[~selector.support_].tolist(), '/tmp/bowl2019/features.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train With Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def standard_scaler(dataset, features, stats=None):\n",
    "    stats = stats or {}\n",
    "    for feature in features:\n",
    "        if feature not in stats:\n",
    "            m = dataset[feature].mean()\n",
    "            s = dataset[feature].std() + 1e-8\n",
    "            stats[feature] = {'mean': m, 'std': s}\n",
    "        dataset[feature] = (dataset[feature] - stats[feature]['mean'])/stats[feature]['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset, features = read_dataset()\n",
    "cnt_features = U.starts_with(features, 'cnt_')\n",
    "standard_scaler(dataset, cnt_features)\n",
    "result_std = adv_cv(dataset, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_feat_imp(result_std.fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train With Grouped Normalization: Session Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def standard_scaler_grouped(dataset, features, grouping_key='session_title'):\n",
    "    def _standard_scaler(x):\n",
    "        m, s = x.mean(), x.std()\n",
    "        return (x - m)/(s + 1e-8)\n",
    "    groups = dataset.groupby(grouping_key)\n",
    "    for feature in features:\n",
    "        dataset[feature] = groups[feature].transform(_standard_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset, features = read_dataset()\n",
    "cnt_features = U.starts_with(features, 'cnt_')\n",
    "standard_scaler_grouped(dataset, cnt_features)\n",
    "result_std_grouped = adv_cv(dataset, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_feat_imp(result_std_grouped.fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train With Grouped Normalization: Installation ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset, features = read_dataset()\n",
    "cnt_features = U.starts_with(features, 'cnt_')\n",
    "standard_scaler_grouped(dataset, cnt_features, grouping_key='installation_id')\n",
    "result_std_inst = adv_cv(dataset, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_feat_imp(result_std_inst.fi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Adversarial CV with Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available:\", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    K = tf.keras.backend\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dataset, features = read_dataset()\n",
    "target_col = 'is_test'\n",
    "cat_cols = ['session_title']\n",
    "num_cols = [f for f in features if f not in cat_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "normalize(dataset, num_cols, grouping_key='session_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_model(num_cols, cat_cols, cat_sizes, \n",
    "                output_size, output_act, loss):\n",
    "    \n",
    "    def prepare_input(data):\n",
    "        return [data[num_cols]] + [data[col].T for col in cat_cols]\n",
    "    \n",
    "    def numerical(input_size):\n",
    "        i = L.Input(shape=(input_size,))\n",
    "        x = L.Dense(2048, activation='relu', use_bias=False)(i)\n",
    "        x = L.BatchNormalization()(x)\n",
    "        x = L.Dropout(0.5)(x)\n",
    "        m = models.Model(inputs=i, outputs=x)\n",
    "        return m\n",
    "    \n",
    "    def categorical(cat_sizes):\n",
    "        inputs, embeds = [], []\n",
    "        for cat_size in cat_sizes:\n",
    "            emb_sz = min(50, cat_size // 2)\n",
    "            i = L.Input(shape=(1,))\n",
    "            x = L.Embedding(output_dim=emb_sz, input_dim=cat_size)(i)\n",
    "            inputs.append(i)\n",
    "            embeds.append(x)\n",
    "        if len(embeds) > 1:\n",
    "            x = L.concatenate(embeds)\n",
    "        x = L.Flatten()(x)\n",
    "        m = models.Model(inputs=inputs, outputs=x)\n",
    "        return m\n",
    "    \n",
    "    with tf.device('/GPU:1'):\n",
    "        num = numerical(len(num_cols))\n",
    "        cat = categorical(cat_sizes)\n",
    "        x = L.concatenate(num.outputs + cat.outputs)\n",
    "        x = L.Dense(1024, activation='relu', use_bias=False)(x)\n",
    "        x = L.BatchNormalization()(x)\n",
    "        x = L.Dropout(0.25)(x)\n",
    "        x = L.Dense(512, activation='relu', use_bias=False)(x)\n",
    "        x = L.BatchNormalization()(x)\n",
    "        x = L.Dropout(0.25)(x)\n",
    "        x = L.Dense(256, activation='relu', use_bias=False)(x)\n",
    "        x = L.BatchNormalization()(x)\n",
    "        x = L.Dropout(0.25)(x)\n",
    "        x = L.Dense(output_size, activation=output_act)(x)\n",
    "        model = models.Model(inputs=num.inputs + cat.inputs, outputs=x)\n",
    "        model.compile(optimizer='rmsprop', loss=root_mean_squared_error)\n",
    "        \n",
    "    return model, prepare_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "folds = GroupKFold(n_splits=5)\n",
    "dataset = dataset.sample(dataset.shape[0])\n",
    "group = dataset['installation_id']\n",
    "X, y = dataset[features], dataset['is_test']\n",
    "oof = np.zeros(len(y), dtype=np.float32)\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(folds.split(X, y, group), 1):\n",
    "    print(f'Training fold #{i}')\n",
    "    x_trn, y_trn = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    x_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    net, split_input = build_model(cat_cols=cat_cols, num_cols=num_cols, \n",
    "                                   cat_sizes=[5], loss='binary_crossentropy',\n",
    "                                   output_size=1, output_act='sigmoid')\n",
    "    net.fit(x=split_input(x_trn), y=y_trn,\n",
    "            validation_data=(split_input(x_val), y_val),\n",
    "            epochs=50, batch_size=2560,\n",
    "            callbacks=[tf.keras.callbacks.EarlyStopping(patience=10)])\n",
    "    probs = net.predict(split_input(x_val))\n",
    "    oof[val_idx] = probs.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y, oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(net, show_shapes=True, rankdir='LR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf]",
   "language": "python",
   "name": "conda-env-tf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
