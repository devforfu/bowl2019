{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp /kaggle/input/data-bowl-2019-external-data/*.py /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "import jupytools.syspath\n",
    "def ignore(*args, **kwargs): pass\n",
    "warnings.warn = ignore\n",
    "jupytools.syspath.add('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import bundle\n",
    "import features as F\n",
    "import selection\n",
    "import utils as U\n",
    "from dataset import load, load_sample, Subset\n",
    "from encode import encode\n",
    "from training import train, inference, submit, EnsembleTrainer, get_default_config\n",
    "from meta import compute_meta_data\n",
    "from metric import optimize_rounding_bounds, make_cappa_metric\n",
    "from normalize import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train and test.\n",
      "(11341042, 11) (17690, 7) (386, 3) (1156414, 11) "
     ]
    }
   ],
   "source": [
    "sample = False\n",
    "if U.on_kaggle():\n",
    "    U.log('Loading test set only.')\n",
    "    tst_data = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\n",
    "else:\n",
    "    if sample:\n",
    "        U.log('Warning: loading train and test data sample.')\n",
    "        trn_data, _, _ = load_sample(Subset.Train, 500_000)\n",
    "        [tst_data] = load_sample(Subset.Test, 500_000)\n",
    "    else:\n",
    "        U.log('Loading train and test.')\n",
    "        trn_data, trn_spec, trn_targ = load(Subset.Train)\n",
    "        [tst_data] = load(Subset.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming train and test data.\n",
      "(11341042, 19) (1156414, 19)\n"
     ]
    }
   ],
   "source": [
    "transform = U.combine(\n",
    "    partial(F.add_feature_combinations, pairs=[('title', 'event_code')]),\n",
    "    partial(F.add_datetime, column='timestamp', prefix='ts'),\n",
    ")\n",
    "\n",
    "if U.on_kaggle():\n",
    "    U.log('Transforming test data only.')\n",
    "    X_tst = transform(tst_data.copy())\n",
    "    U.log(X_tst.shape)\n",
    "else:\n",
    "    U.log('Transforming train and test data.')\n",
    "    X_tst = transform(tst_data.copy())\n",
    "    X_trn = transform(trn_data.copy())\n",
    "    U.log(X_trn.shape, X_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing meta using train and test datasets.\n",
      "Saving computed meta on disk.\n"
     ]
    }
   ],
   "source": [
    "if U.on_kaggle():\n",
    "    U.log('Reading pre-computed meta from disk.')\n",
    "    meta = bundle.meta()\n",
    "else:\n",
    "    U.log('Computing meta using train and test datasets.')\n",
    "    meta = compute_meta_data(X_trn, X_tst)\n",
    "    U.log('Saving computed meta on disk.')\n",
    "    bundle.save_meta(meta, 'meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing train and test datasets.\n",
      "Running algorithm in train mode.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e0c06427c441338936f560f4b9b6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running algorithm in test mode.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2041e1c19449bf831d774f863d72e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extractor = F.FeaturesExtractor([\n",
    "    F.CountingFeatures(meta),\n",
    "    F.PerformanceFeatures(meta),\n",
    "    F.VarietyFeatures(meta),\n",
    "    F.EventDataFeatures(meta),\n",
    "    F.FeedbackFeatures(meta)\n",
    "])\n",
    "\n",
    "algo = F.InMemoryAlgorithm(extractor, meta, num_workers=12)\n",
    "\n",
    "cat_cols = ['session_title']\n",
    "\n",
    "if U.on_kaggle():\n",
    "    U.log('Preparing test dataset.')\n",
    "    X_tst = algo.run(X_tst, test=True)\n",
    "    encoders = bundle.encoders()\n",
    "    X_tst, _ = encode(X_tst, cat_cols, encoders=encoders)\n",
    "else:\n",
    "    U.log('Preparing train and test datasets.')\n",
    "    X_trn = algo.run(X_trn)\n",
    "    X_tst = algo.run(X_tst, test=True)\n",
    "    X_trn, encoders = encode(X_trn, cat_cols)\n",
    "    X_tst, _ = encode(X_tst, cat_cols, encoders=encoders)\n",
    "    bundle.save(encoders, 'encoders')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running post-processing on train and test sets.\n"
     ]
    }
   ],
   "source": [
    "if U.on_kaggle():\n",
    "    U.log('Running post-processing on test set only.')\n",
    "    F.add_user_wise_features(X_tst, meta)\n",
    "else:\n",
    "    U.log('Running post-processing on train and test sets.')\n",
    "    F.add_user_wise_features(X_trn, meta)\n",
    "    F.add_user_wise_features(X_tst, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn.to_pickle('/tmp/X_trn.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tst.to_pickle('/tmp/X_tst.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn = pd.read_pickle('/tmp/X_trn.pickle')\n",
    "X_tst = pd.read_pickle('/tmp/X_tst.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_col = 'installation_id'\n",
    "U.log(f'Normalizing dataset using column for grouping: {group_col}')\n",
    "norm_dataset = X_tst if U.on_kaggle() else X_trn\n",
    "cnt_cols = U.starts_with(norm_dataset.columns, 'cnt_')\n",
    "normalize(norm_dataset, cnt_cols, grouping_key=group_col, method='min-max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn = pd.read_pickle('/tmp/X_trn.pickle')\n",
    "X_tst = pd.read_pickle('/tmp/X_tst.pickle')\n",
    "cappa = make_cappa_metric(X_trn['accuracy_group'])\n",
    "features = [c for c in X_trn.columns \n",
    "            if c not in ('installation_id', 'game_session', 'accuracy_group')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'lightgbm'\n",
    "trainer = EnsembleTrainer(algo=model_type, cv_metrics={'cappa': cappa})\n",
    "fold = GroupKFold(n_splits=5)\n",
    "config = get_default_config(model_type)\n",
    "result = trainer.train(X_trn, features=features, fold=fold, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cappa(X_trn['accuracy_group'].values, result.oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features from event_data\n",
    "# https://www.kaggle.com/c/data-science-bowl-2019/discussion/124028\n",
    "\n",
    "# truncated validation\n",
    "# https://www.kaggle.com/ragnar123/truncated-val\n",
    "# https://www.kaggle.com/c/data-science-bowl-2019/discussion/120790\n",
    "\n",
    "# params = {'boosting_type': 'gbdt', \n",
    "#           'metric': 'rmse', \n",
    "#           'objective': 'regression', \n",
    "#           'eval_metric': 'cappa', \n",
    "#           'n_jobs': -1, \n",
    "#           'seed': 42, \n",
    "#           'num_leaves': 26, \n",
    "#           'learning_rate': 0.077439684887749, \n",
    "#           'max_depth': 33, \n",
    "#           'lambda_l1': 3.27791989030057, \n",
    "#           'lambda_l2': 1.3047627805931334, \n",
    "#           'bagging_fraction': 0.896924978584253, \n",
    "#           'bagging_freq': 1, \n",
    "#           'colsample_bytree': 0.8710772167017853}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = X_trn.columns.tolist()\n",
    "cnt_cols = U.starts_with(columns, 'cnt_')\n",
    "perf_cols = U.starts_with(columns, 'perf_')\n",
    "var_cols = U.starts_with(columns, 'var_')\n",
    "user_cols = U.starts_with(columns, 'user_')\n",
    "event_cols = U.starts_with(columns, 'event_')\n",
    "cat_cols = ['session_title']\n",
    "cols = cnt_cols + perf_cols + var_cols + user_cols + event_cols + cat_cols\n",
    "\n",
    "features_groups = [\n",
    "    ('cnt+perf+var', cnt_cols + perf_cols + var_cols),\n",
    "    ('cnt+perf+user', cnt_cols + perf_cols + user_cols),\n",
    "    ('cnt+perf+cat', cnt_cols + perf_cols + cat_cols),\n",
    "    ('cnt+perf+var+user+cat', cnt_cols + perf_cols + var_cols + user_cols + cat_cols),\n",
    "    ('event+cnt+perf', event_cols + cnt_cols + perf_cols),\n",
    "    ('event+cnt+perf+user', event_cols + cnt_cols + perf_cols + user_cols),\n",
    "    ('event+cnt+perf+var', event_cols + cnt_cols + perf_cols + var_cols),\n",
    "    ('event+cnt+pert+cat', event_cols + cnt_cols + perf_cols + cat_cols),\n",
    "    ('event+cnt+perf+user+var+cat', \n",
    "     event_cols + cnt_cols + perf_cols + user_cols + var_cols + cat_cols),\n",
    "    ('all', cols),\n",
    "    ('all-event', [c for c in cols if c not in event_cols])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "from training import EnsembleTrainer, get_default_config\n",
    "\n",
    "model_type = 'lightgbm'\n",
    "trainer = EnsembleTrainer(algo=model_type, cv_metrics={'cappa': cappa})\n",
    "fold = GroupKFold(n_splits=5)\n",
    "config = get_default_config(model_type)\n",
    "U.set_nested(config, 'model_params.feature_fraction', 0.8)\n",
    "U.set_nested(config, 'model_params.bagging_fraction', 0.75)\n",
    "U.set_nested(config, 'model_params.bagging_freq', 1)\n",
    "\n",
    "results = []\n",
    "for col_group, features in features_groups:\n",
    "    U.log(f'Training columns group: {col_group}')\n",
    "    result = trainer.train(X_trn, features=features, fold=fold, config=config)\n",
    "    results.append((col_group, result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = pd.DataFrame([\n",
    "    OrderedDict([('features', name)] + list(result.cv.items())) \n",
    "    for name, result in results])\n",
    "cappa_cols = U.starts_with(report.columns, 'cv_cappa')\n",
    "report['mean'] = report[cappa_cols].mean(axis=1)\n",
    "report['std'] = report[cappa_cols].std(axis=1)\n",
    "report.sort_values(by=['mean'], inplace=True, ascending=False)\n",
    "report.reset_index(drop=True, inplace=True)\n",
    "report.to_csv(f'report_{U.now()}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_best(col):\n",
    "    if not col.name.startswith('cv_cappa_'):\n",
    "        return [''] * len(col)\n",
    "    is_best = col.index == col.argmax()\n",
    "    return ['background-color: salmon' if idx else '' for idx in is_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.style.apply(highlight_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "sample = trn_data.sample(1_000_000)\n",
    "event_data = pd.io.json.json_normalize(sample.event_data.apply(json.loads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import existing_info\n",
    "stat_info = existing_info(event_data).T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "f, ax = plt.subplots(figsize=(8, 12))\n",
    "ax = sns.barplot(x='Percent', y='index', data=stat_info.head(40))\n",
    "ax.set_title('Most Frequent Features')\n",
    "ax.set_ylabel('Features')\n",
    "ax.grid(True, linestyle='dotted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U.show_all(event_data['identifier'].fillna('n/a').value_counts().reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = event_data['identifier'].fillna('n/a').value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_identifier(x):\n",
    "    if U.starts_with_any(x, ['Dot', 'Buddy', 'Mom', 'Cleo']):\n",
    "        parts = x.split(',')\n",
    "        if len(parts) > 1:\n",
    "            prefix = os.path.commonprefix(parts)\n",
    "            n = len(prefix)\n",
    "            trimmed = [U.camel_to_snake(part[n:]) for part in parts]\n",
    "            string = '_'.join(trimmed)\n",
    "        else:\n",
    "            prefix = ''\n",
    "            string = U.camel_to_snake(x.replace('_', ''))\n",
    "        result = f'{prefix}{string}'\n",
    "        return result.lower()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE_FEEDBACK = set([\n",
    "    'dot_so_cool',\n",
    "    'dot_great_job',\n",
    "    'ohWow',\n",
    "    'wowSoCool',\n",
    "    'thatLooksSoCool',\n",
    "    'niceJob',\n",
    "    'tub_success',\n",
    "    'water_success',\n",
    "    'soap_success',\n",
    "    'dot_whoa_so_cool',\n",
    "    'dot_wow',\n",
    "    'dot_amazing',\n",
    "    'cleo_awe_of_your_skills',\n",
    "    'greatJob_1306',\n",
    "    'dot__you_did_it_sfx_completedtask',\n",
    "    'RIGHTANSWER3',\n",
    "    'RIGHTANSWER2',\n",
    "    'RIGHTANSWER1',\n",
    "    'AWESOME',\n",
    "    'dot_awesome',\n",
    "    'cleo_amazing_powers',\n",
    "    'dot_nice_work_all_match',\n",
    "    'GreatFlying',\n",
    "    'youDidIt_1305'\n",
    "])\n",
    "\n",
    "NEGATIVE_FEEDBACK = set([\n",
    "    'IncorrectTooHeavy_touch',\n",
    "    'IncorrectTooLight',\n",
    "    'dot_uhoh_need_try_again',\n",
    "    'dot_so_low',\n",
    "    'buddy_dinosaurs_awfully_thirsty_fill_clouds',\n",
    "    'cleo_bowl_too_light',\n",
    "    'dot_whoops_too_short',\n",
    "    'REMOVE_WEIGHT',\n",
    "    'NOT_THAT_HEAVY',\n",
    "    'dot_uh_oh_too_tall',\n",
    "    'wrong2',\n",
    "    'wrong1',\n",
    "    'tryAgain0_1333',\n",
    "    'ADD_MORE_WEIGHT',\n",
    "    'cleo_bowl_too_light_remember_heavier_bowl',\n",
    "    'dot_whoops_not_balanced',\n",
    "    'WrongOver',\n",
    "    'wrongMore',\n",
    "    'WrongBetweenTree',\n",
    "    'wrongFewer',\n",
    "    'WrongBetweenCliff',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_feedback(x):\n",
    "    return ('positive' if x in POSITIVE_FEEDBACK else\n",
    "            'negative' if x in NEGATIVE_FEEDBACK else\n",
    "            'other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = 'dot', 'buddy', 'mom', 'cleo'\n",
    "normalized = cnt['index'].map(transform_identifier)\n",
    "character_identifiers = normalized.map(lambda x: U.starts_with_any(x, characters))\n",
    "edi = pd.DataFrame({'identifier': normalized[character_identifiers]})\n",
    "edi['character'] = event_data_ident['identifier'].map(lambda x: x.split('_')[0])\n",
    "edi['feedback'] = event_data_ident['identifier'].map(transform_feedback)\n",
    "U.show_all(edi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "U.show_all(normalized.reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U.show_all(cnt['index'].map(transform_identifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Dot_SoCool' --> 'dot_so_cool'\n",
    "# 'Dot_AllDoneTapThis' --> 'dot_all_done'\n",
    "# 'Dot_FillItUp' --> 'dot_fill_it_up'\n",
    "# 'Dot_GreatJob' --> 'dot_great_job'\n",
    "# 'Dot_TryWall' --> 'dot_try_wall'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_keys = stat_info['index'][stat_info['Percent'] >= 5.].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round_df = event_data['round'].fillna(0).value_counts().reset_index()\n",
    "round_df['index'] = round_df['index'].astype(int)\n",
    "round_df.sort_values(by='index', inplace=True)\n",
    "round_df.plot(x='index', y='round')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.isnan(event_data['coordinates.x'].iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data['coordinates.x'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data['media_type'].fillna('unknown').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data['source'].fillna('N/A').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = event_data['level'].fillna(0)\n",
    "pd.cut(levels, [-np.inf, 3, 5, 8, 13, 21, np.inf], labels=[0, 1, 2, 3, 4, 5]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data['size'].fillna(0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_data['weight'].fillna(0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# round: float with NaNs\n",
    "# coordinates.(x|y): float with NaNs, but presumably integer\n",
    "# coordinates.stage_(width|height): float with NaNs, but presumably categorical\n",
    "#\n",
    "# description: text messages, try to convert into categoricals?\n",
    "#     (event_data['description'].fillna('n/a').value_counts()\n",
    "#      .rename('count').reset_index().rename(columns={'index': 'text'}))\n",
    "#\n",
    "# identifier: some string, probably concatenated with commas; most simple is to compute len\n",
    "# event_data['identifier'].fillna('n/a').str.split(',').apply(len)\n",
    "#\n",
    "# media_type: categorical string\n",
    "# event_data['media_type'].fillna('n/a').value_counts()\n",
    "#\n",
    "# duration: should already exist in the features set\n",
    "# total_duration: probably also present in the features\n",
    "#\n",
    "# source: also some kind of categorical string\n",
    "# event_data['source'].fillna('n/a').value_counts()\n",
    "#\n",
    "# level: integer feature, can be used as a cumulative metric (?)\n",
    "# event_data['level'].fillna('n/a').value_counts()\n",
    "#\n",
    "# correct: defines if attempt was done, is already used in feature processing\n",
    "# \n",
    "# size: integer feature\n",
    "# event_data['size'].fillna('n/a').value_counts()\n",
    "#\n",
    "# weight: one more integer feature\n",
    "# event_data['weight'].fillna('n/a').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Features Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# selector = selection.FeatureSelection(\n",
    "#     rules=[\n",
    "#         ('nonzero', selection.non_zero_rows_and_cols),\n",
    "#     ],\n",
    "#     ignore_cols=[\n",
    "#         'accuracy_group', \n",
    "#         'installation_id', \n",
    "#         'game_session'\n",
    "#     ]\n",
    "# )\n",
    "# if U.on_kaggle():\n",
    "#     U.log('Loading relevant features list from disk.')\n",
    "#     features = bundle.features()\n",
    "# else:\n",
    "#     U.log('Deriving relevant features from train dataset.')\n",
    "#     features = selector.select(X_trn)\n",
    "#     bundle.save(features, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if U.on_kaggle():\n",
    "    U.log('Loading relevant features list from disk.')\n",
    "    features = bundle.features()\n",
    "else:\n",
    "#     columns = features\n",
    "#     cnt_cols = U.starts_with(columns, 'cnt_')\n",
    "#     perf_cols = U.starts_with(columns, 'perf_')\n",
    "#     var_cols = U.starts_with(columns, 'var_')\n",
    "#     user_cols = U.starts_with(columns, 'user_')\n",
    "#     ts_cols = U.starts_with(columns, 'ts_')\n",
    "#     event_cols = U.starts_with(columns, 'event_')\n",
    "#     cat_cols = ['session_title']\n",
    "#     features = cnt_cols + perf_cols + user_cols + var_cols + event_cols + cat_cols\n",
    "    features = [x for x in X_trn.columns \n",
    "                if x not in ('installation_id', 'game_session', 'accuracy_group')]\n",
    "    bundle.save(features, 'features')\n",
    "U.log(f'Total number of features: {len(features)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "algo = 'lightgbm'\n",
    "version = '020'\n",
    "\n",
    "if U.on_kaggle():\n",
    "    U.log('Inference on Kaggle.')\n",
    "    features = bundle.features()\n",
    "    bounds = bundle.bounds()\n",
    "    predicted = inference(X_tst, features, bounds=bounds, model=algo, version=version)\n",
    "    U.log('Saving predictions on disk.')\n",
    "    filename = submit(predicted)\n",
    "    submit_df = pd.read_csv(filename)\n",
    "    U.log('First 20 submission rows:')\n",
    "    display(submit_df.head(20))\n",
    "    \n",
    "else:\n",
    "    U.log(f'Training model: {algo}')\n",
    "    cappa = make_cappa_metric(X_trn['accuracy_group'])\n",
    "    trainer = EnsembleTrainer(algo=algo, cv_metrics={'cappa': cappa})\n",
    "    fold = GroupKFold(n_splits=5)\n",
    "    config = get_default_config(algo)\n",
    "    U.set_nested(config, 'model_params.feature_fraction', 0.8)\n",
    "    U.set_nested(config, 'model_params.bagging_fraction', 0.75)\n",
    "    U.set_nested(config, 'model_params.bagging_freq', 1)\n",
    "    result = trainer.train(X_trn, features=features, fold=fold, config=config)\n",
    "    U.log('Saving the trained models')\n",
    "    bundle.save(result.models, f'models_{algo}_{version}')\n",
    "    U.log('Saving the optimal rounding bounds')\n",
    "    bounds = optimize_rounding_bounds(result.oof, X_trn['accuracy_group'].values)\n",
    "    U.log(f'Optimal bounds: {bounds}')\n",
    "    bundle.save(bounds, 'bounds')\n",
    "    U.log(f'Final features number: {len(features)}')\n",
    "    bundle.save(features, 'features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "if not U.on_kaggle():\n",
    "    import os\n",
    "    features = bundle.features()\n",
    "    bounds = bundle.bounds()\n",
    "    filename = submit(inference(X_tst, features, bounds, model=algo, version=version))\n",
    "    assert os.path.exists(filename)\n",
    "    assert pd.read_csv(filename).shape[0] == 1000\n",
    "    bundle.package(folder='/home/ck/data/bowl2019/external/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.read_csv('submission.csv')['accuracy_group'].value_counts().reset_index().sort_values(by='index').set_index('index').plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_trn['accuracy_group'].value_counts().reset_index().sort_values(by='index').set_index('index').plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
