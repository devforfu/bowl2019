{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "import jupytools.syspath\n",
    "def ignore(*args, **kwargs): pass\n",
    "warnings.warn = ignore\n",
    "jupytools.syspath.add('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict, Counter, OrderedDict\n",
    "from functools import partial\n",
    "from multiprocessing import cpu_count\n",
    "from os.path import join\n",
    "\n",
    "import feather\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import utils as U\n",
    "from basedir import TRAIN, TEST\n",
    "from dataset import load, load_sample, Subset, to_accuracy_group\n",
    "from metric import qwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11341042, 11) (17690, 7) (386, 3) (1156414, 11) "
     ]
    }
   ],
   "source": [
    "use_sample = False\n",
    "loader = partial(load_sample, size=100_000) if use_sample else load\n",
    "trn_data, trn_targ, trn_spec = loader(Subset.Train)\n",
    "[tst_data] = loader(Subset.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpdir = '/tmp/bowl2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_feature_combinations(data, pairs):\n",
    "    for c1, c2 in pairs:\n",
    "        assert c1 in data.columns, f'Column not found: {c1}'\n",
    "        assert c2 in data.columns, f'Column not found: {c2}'\n",
    "        data[f'{c1}_{c2}'] = data[c1].astype(str).str.cat(data[c2].astype(str), '_')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime(data, column, prefix=None, with_time=True):\n",
    "    data[column] = pd.to_datetime(data[column])\n",
    "    prefix = U.default(prefix, re.sub('[Dd]ate$', '', column))\n",
    "    attrs = ('Year', 'Month', 'Week', 'Day', 'Dayofweek')\n",
    "    if with_time:\n",
    "        attrs += ('Hour', 'Minute')\n",
    "    for attr in attrs:\n",
    "        data[f'{prefix}_{attr}'] = getattr(data[column].dt, attr.lower())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cyclical(data, prefix, features=('Year', 'Month', 'Week', 'Hour', 'Minute'),\n",
    "                 modulo=None):\n",
    "    modulo = modulo or {}\n",
    "    for feature in features:\n",
    "        column = f'{prefix}_{feature}'\n",
    "        m = modulo.get(feature, 23.0)\n",
    "        data[f'{column}_sin'] = np.sin(2*np.pi*data[column] / m)\n",
    "        data[f'{column}_cos'] = np.cos(2*np.pi*data[column] / m)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = U.combine(\n",
    "    partial(add_feature_combinations, pairs=[('title', 'event_code')]),\n",
    "    partial(add_datetime, column='timestamp', prefix='ts'),\n",
    "    partial(add_cyclical, prefix='ts')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn = transform(trn_data.copy())\n",
    "X_tst = transform(tst_data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_meta_data(dataset, *datasets):\n",
    "    datasets = [dataset] + list(datasets)\n",
    "    uniq = OrderedDict()\n",
    "    uniq['title_event_code'] = U.unique(datasets, column='title_event_code')\n",
    "    uniq['title'] = U.unique(datasets, column='title')\n",
    "    uniq['event_code'] = U.unique(datasets, column='event_code')\n",
    "    uniq['event_id'] = U.unique(datasets, column='event_id')\n",
    "    uniq['world'] = U.unique(datasets, column='world')\n",
    "    uniq['type'] = U.unique(datasets, column='type')\n",
    "    asm_datasets = [ds.query('type == \"Assessment\"') for ds in datasets]\n",
    "    uniq['assessment_titles'] = U.unique(asm_datasets, column='title')\n",
    "    win_codes = {t: 4100 for t in uniq['title']}\n",
    "    win_codes['Bird Measurer (Assessment)'] = 4110\n",
    "    meta = {'win_codes': win_codes, **uniq}\n",
    "    return U.named_tuple('Meta', **meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = compute_meta_data(X_trn, X_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attempt_outcomes(session, meta):\n",
    "    event_code = meta.win_codes.get(session.title.iloc[0], 4100)\n",
    "    total_attempts = session.query(f'event_code == {event_code}')\n",
    "    pos = total_attempts.event_data.str.contains('true').sum()\n",
    "    neg = total_attempts.event_data.str.contains('false').sum()\n",
    "    summary = dict(pos=pos, neg=neg, total=(pos + neg))\n",
    "    return U.named_tuple('Trial', **summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_info(session, meta, test):\n",
    "    session_type = session['type'].iloc[0]\n",
    "    assessment = session_type == 'Assessment'\n",
    "    outcomes = attempt_outcomes(session, meta) if assessment else None\n",
    "    should_include = (\n",
    "        (assessment and test) or \n",
    "        (assessment and (len(session) > 1) and outcomes.total > 0))\n",
    "    duration = session.timestamp.iloc[-1] - session.timestamp.iloc[0]\n",
    "    return U.named_tuple(\n",
    "        name='Info', \n",
    "        installation_id=session['installation_id'].iloc[0],\n",
    "        game_session=session['game_session'].iloc[0],\n",
    "        session_title=session['title'].iloc[0],\n",
    "        session_type=session_type,\n",
    "        is_assessment=assessment,\n",
    "        should_include=should_include,\n",
    "        outcomes=outcomes,\n",
    "        duration_seconds=duration.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_user = X_trn.query('installation_id == \"0235fe9a\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_features(user, meta, test=False):\n",
    "    rows = []\n",
    "    for _, session in user.groupby('game_session', sort=False):\n",
    "        info = session_info(session, meta, test)\n",
    "        if info.should_include:\n",
    "            features = OrderedDict([\n",
    "                ('installation_id', info.installation_id),\n",
    "                ('game_session', info.game_session),\n",
    "                ('session_title', info.session_title)\n",
    "            ])\n",
    "            rows.append(features)\n",
    "    return [rows[-1]] if test else rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counting_features(user, meta, test=False):\n",
    "    cnt_title_event_code = U.init_dict(meta.title_event_code)\n",
    "    cnt_title = U.init_dict(meta.title)\n",
    "    cnt_event_code = U.init_dict(meta.event_code)\n",
    "    cnt_event_id = U.init_dict(meta.event_id)\n",
    "    cnt_activities = U.init_dict(meta.type)\n",
    "    \n",
    "    last_activity = None\n",
    "    \n",
    "    def update_counters(cnt, sess, column):\n",
    "        uniq_counts = Counter(sess[column])\n",
    "        for k, v in uniq_counts.items():\n",
    "            if k in cnt:\n",
    "                cnt[k] += v\n",
    "    \n",
    "    rows = []\n",
    "    for _, session in user.groupby('game_session', sort=False):\n",
    "        info = session_info(session, meta, test)\n",
    "        \n",
    "        if info.should_include:\n",
    "            features = OrderedDict()\n",
    "            counters = {**cnt_activities,\n",
    "                        **cnt_title_event_code,\n",
    "                        **cnt_title,\n",
    "                        **cnt_event_code,\n",
    "                        **cnt_event_id}\n",
    "            features.update([(f'cnt_{k}', v) for k, v in counters.items()])\n",
    "            rows.append(features)\n",
    "            \n",
    "        update_counters(cnt_title_event_code, session, 'title_event_code')\n",
    "        update_counters(cnt_title, session, 'title')\n",
    "        update_counters(cnt_event_code, session, 'event_code')\n",
    "        update_counters(cnt_event_id, session, 'event_id')\n",
    "        \n",
    "        if last_activity is None or last_activity != info.session_type:\n",
    "            cnt_activities[info.session_type] += 1\n",
    "            last_activity = info.session_type\n",
    "    \n",
    "    return [rows[-1]] if test else rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(counting_features(test_user, meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_features(user, meta, test=False):\n",
    "    acc_accuracy = 0\n",
    "    acc_accuracy_group = 0\n",
    "    acc_correct_attempts = 0\n",
    "    acc_incorrect_attempts = 0\n",
    "    acc_actions = 0\n",
    "    \n",
    "    durations = []\n",
    "    accuracy_groups = U.init_dict([0, 1, 2, 3])\n",
    "    last_accuracy_title = U.init_dict([f'acc_{t}' for t in meta.title], -1)\n",
    "    \n",
    "    n_rows = 0\n",
    "    \n",
    "    rows = []\n",
    "    for _, session in user.groupby('game_session', sort=False):\n",
    "        info = session_info(session, meta, test)\n",
    "        \n",
    "        if info.should_include:\n",
    "            features = OrderedDict()\n",
    "            features['acc_attempts_pos'] = acc_correct_attempts\n",
    "            features['acc_attempts_neg'] = acc_incorrect_attempts\n",
    "            acc_correct_attempts += info.outcomes.pos\n",
    "            acc_incorrect_attempts += info.outcomes.neg\n",
    "            \n",
    "            features['acc_accuracy'] = U.savediv(acc_accuracy, n_rows)\n",
    "            accuracy = U.savediv(info.outcomes.pos, info.outcomes.total)\n",
    "            acc_accuracy += accuracy\n",
    "            \n",
    "            features.update(last_accuracy_title)\n",
    "            last_accuracy_title[f'acc_{info.session_title}'] = accuracy\n",
    "            \n",
    "            features['accuracy_group'] = to_accuracy_group(accuracy)\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            \n",
    "            features['acc_accuracy_group'] = U.savediv(acc_accuracy_group, n_rows)\n",
    "            acc_accuracy_group += features['accuracy_group']\n",
    "\n",
    "            features['acc_actions'] = acc_actions\n",
    "            \n",
    "            features['duration_mean'] = np.mean(durations) if durations else 0\n",
    "            durations.append(info.duration_seconds)\n",
    "\n",
    "            rows.append(features)\n",
    "            n_rows += 1\n",
    "        \n",
    "        acc_actions += len(session)\n",
    "    \n",
    "    return [rows[-1]] if test else rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(performance_features(test_user, meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamp_features(user, meta, test=False):\n",
    "    acc = defaultdict(list)\n",
    "\n",
    "    rows = []\n",
    "    \n",
    "    for _, session in user.groupby('game_session', sort=False):\n",
    "        info = session_info(session, meta, test)\n",
    "\n",
    "        if info.should_include:\n",
    "            features = OrderedDict()\n",
    "            for dt in ('Year', 'Month', 'Week', 'Hour', 'Minute'):\n",
    "                for angle in ('sin', 'cos'):\n",
    "                    key = f'ts_{dt}_{angle}'\n",
    "                    acc[key] += session[key].tolist()\n",
    "                    features[f'{key}_mean'] = np.mean(acc[key])\n",
    "                    features[f'{key}_std'] = np.std(acc[key])\n",
    "                    \n",
    "            rows.append(features)\n",
    "    \n",
    "    return [rows[-1]] if test else rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(timestamp_features(test_user, meta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_groups_on_disk(data, output_dir='/tmp/bowl2019/groups'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    filenames = []\n",
    "    for iid, group in tqdm(data.groupby('installation_id')):\n",
    "        filename = os.path.join(output_dir, iid)\n",
    "        group.reset_index(drop=True).to_feather(filename)\n",
    "        filenames.append(filename)\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f41d1bcd9274c1c9db41f5429250a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=17000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trn_files = save_groups_on_disk(X_trn, output_dir=f'{tmpdir}/trn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db16a68cc4cf4d198a87409f5ed8267d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tst_files = save_groups_on_disk(X_tst, output_dir=f'{tmpdir}/tst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class FeatureExtractor:\n",
    "#     def __new__(cls, steps, meta, backend='disk', **params):\n",
    "#         if backend == 'disk':\n",
    "#             ext = DiskExtractor\n",
    "#         elif backend == 'memory':\n",
    "#             ext = MemoryExtractor\n",
    "#         else:\n",
    "#             raise ValueError(f'unknown backend: {backend}')\n",
    "#         return object.__new__(ext)\n",
    "    \n",
    "#     def __init__(self, steps, meta, pbar=True,\n",
    "#                  test=False, num_workers=cpu_count(),\n",
    "#                  **params):\n",
    "#         self.steps = steps\n",
    "#         self.meta = meta\n",
    "#         self.pbar = pbar\n",
    "#         self.test = test\n",
    "#         self.num_workers = num_workers\n",
    "    \n",
    "#     def __call__(self, data):\n",
    "#         self.extract(data)\n",
    "        \n",
    "#     def extract(self, data):\n",
    "#         raise NotImplementedError()\n",
    "    \n",
    "    \n",
    "# class DiskExtractor(FeatureExtractor):\n",
    "#     def __init__(self, output_dir='/tmp/bowl2019', files_per_batch=16, **params):\n",
    "#         super().__init__(**params)\n",
    "#         self.output_dir = output_dir\n",
    "#         self.files_per_batch = files_per_batch\n",
    "        \n",
    "#     def extract(self, filenames):\n",
    "#         os.makedirs(self.output_dir, exist_ok=True)\n",
    "        \n",
    "#         def _extract(filename):\n",
    "#             df = feather.read_dataframe(filename)\n",
    "#             features = [\n",
    "#                 pd.DataFrame(f(df, self.meta, self.test)) \n",
    "#                 for f in self.steps]\n",
    "#             return pd.conact(features, axis=1)\n",
    "        \n",
    "#         def _save(pair):\n",
    "#             dataframe, filename = pair\n",
    "#             name = os.path.basename(filename)\n",
    "#             output_file = os.path.join(self.output_dir, name)\n",
    "#             dataframe = dataframe.reset_index(drop=True)\n",
    "#             dataframe.to_pickle(output_file)\n",
    "#             return output_file\n",
    "        \n",
    "#         chunks = list(U.chunks(filenames, self.files_per_batch))\n",
    "#         if self.pbar:\n",
    "#             chunks = tqdm(chunks)\n",
    "        \n",
    "#         output_files = []\n",
    "#         n = self.num_workers\n",
    "#         for chunk in chunks:\n",
    "#             breakpoint()\n",
    "#             datasets = U.parallel(_extract, chunk, num_workers=n)\n",
    "#             saved_files = U.parallel(_save, zip(datasets, chunk), num_workers=n)\n",
    "#             output_files.extend(saved_files)\n",
    "        \n",
    "#         return output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractor = FeatureExtractor(\n",
    "#     backend='disk',\n",
    "#     meta=meta,\n",
    "#     steps=[\n",
    "#         id_features,\n",
    "#         counting_features, \n",
    "#         performance_features, \n",
    "#         timestamp_features\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractor(trn_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_from_disk(filenames, meta, funcs, files_per_batch=16, \n",
    "                      num_workers=cpu_count(), pbar=True, test=False,\n",
    "                      output_dir='/tmp/bowl2019/prepared'):\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    def extract(filename):\n",
    "        df = feather.read_dataframe(filename)\n",
    "        features = [pd.DataFrame(f(df, meta, test)) for f in funcs]\n",
    "        return pd.concat(features, axis=1)\n",
    "    \n",
    "    def save(pair):\n",
    "        dataframe, filename = pair\n",
    "        name = os.path.basename(filename)\n",
    "        output_file = os.path.join(output_dir, name)\n",
    "        dataframe = dataframe.reset_index(drop=True)\n",
    "        dataframe.to_pickle(output_file)\n",
    "        return output_file\n",
    "    \n",
    "    chunks = list(U.chunks(filenames, files_per_batch))\n",
    "    if pbar:\n",
    "        chunks = tqdm(chunks)\n",
    "\n",
    "    output_files = []\n",
    "    for chunk in chunks:\n",
    "        datasets = U.parallel(extract, chunk, num_workers=num_workers)\n",
    "        saved_files = U.parallel(save, zip(datasets, chunk), num_workers=num_workers)\n",
    "        output_files.extend(saved_files)\n",
    "        \n",
    "    return output_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    meta=meta, \n",
    "    funcs=[\n",
    "        id_features,\n",
    "        counting_features, \n",
    "        performance_features, \n",
    "        timestamp_features\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_prep_files = process_from_disk(filenames=trn_files, \n",
    "                                   output_dir=f'{tmpdir}/trn_prep', \n",
    "                                   **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_prep_files = process_from_disk(filenames=tst_files, \n",
    "                                   output_dir=f'{tmpdir}/tst_prep',\n",
    "                                   test=True, \n",
    "                                   **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing(filenames, meta, pbar=True, output_dir='/tmp/bowl2019/post'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    def transform(dataframe, key, agg): \n",
    "        return dataframe.groupby('installation_id')[key].transform(agg)\n",
    "    \n",
    "    if pbar:\n",
    "        filenames = tqdm(filenames)\n",
    "    events = [f'cnt_{code}' for code in meta.event_code]\n",
    "    processed_files = []\n",
    "    for filename in filenames:\n",
    "        name = os.path.basename(filename)\n",
    "        df = pd.read_pickle(filename)\n",
    "        if df.empty:\n",
    "            continue\n",
    "        df['installation_session_count'] = len(df['cnt_Clip'])\n",
    "        df['installation_duration_mean'] = df['duration_mean'].mean()\n",
    "        df['installation_title_nunique'] = df['session_title'].nunique()\n",
    "        df['installation_events_sum'] = df[events].sum(axis=1)\n",
    "        df['installation_events_mean'] = df['installation_events_sum'].mean()\n",
    "        new_file = os.path.join(output_dir, name)\n",
    "        df.to_pickle(new_file)\n",
    "        processed_files.append(new_file)\n",
    "    return processed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_prep_files = post_processing(trn_prep_files, meta, output_dir=f'{tmpdir}/trn_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_prep_files = post_processing(tst_prep_files, meta, output_dir=f'{tmpdir}/tst_post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_meta(meta, filename): \n",
    "    joblib.dump(meta._asdict(), filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meta(filename):\n",
    "    meta = joblib.load(filename)\n",
    "    return U.named_tuple('Meta', **meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_meta(meta, f'{tmpdir}/meta.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore Saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = load_meta(f'{tmpdir}/meta.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_root = '/tmp/bowl2019/trn_post'\n",
    "trn_files = [f'{files_root}/{fn}' for fn in os.listdir(files_root)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(dataset, columns, encoders=None):\n",
    "    encoders = encoders or {}\n",
    "    for column in columns:\n",
    "        encoder = encoders.get(column, {})\n",
    "        if encoder:\n",
    "            dataset[column] = dataset[column].map(encoders.get(column, -1))\n",
    "        else:\n",
    "            encoded, decoder = pd.factorize(dataset[column])\n",
    "            dataset[column] = encoded\n",
    "            encoders[column] = {k:i for i, k in enumerate(decoder)}\n",
    "    return dataset, encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_from_files(filenames):\n",
    "    dataset = pd.concat([\n",
    "        pd.read_pickle(filename) \n",
    "        for filename in filenames], axis=0)\n",
    "    dataset = dataset.reset_index(drop=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn, title_enc = encode(read_dataset_from_files(trn_files), \n",
    "                          columns=['session_title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_trn.isna().sum().sum() == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'session_title': {'Cart Balancer (Assessment)': 0,\n",
       "  'Chest Sorter (Assessment)': 1,\n",
       "  'Cauldron Filler (Assessment)': 2,\n",
       "  'Mushroom Sorter (Assessment)': 3,\n",
       "  'Bird Measurer (Assessment)': 4}}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_features(dataset):\n",
    "    def nonzero(x): return not np.allclose(x, 0)\n",
    "    columns = ['accuracy_group', 'installation_id', 'game_session']\n",
    "    dataset = dataset.drop(columns=columns)\n",
    "    nonzero_rows = dataset.sum(axis=1).map(nonzero)\n",
    "    nonzero_cols = dataset.sum(axis=0).map(nonzero)\n",
    "    features = dataset.loc[nonzero_rows, nonzero_cols].columns.tolist()\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_feat = get_relevant_features(X_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/bowl2019/features.joblib']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(rel_feat, f'{tmpdir}/features.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/bowl2019/title_enc.joblib']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(title_enc, f'{tmpdir}/title_enc.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trn.to_feather(f'{tmpdir}/X_trn.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import scipy\n",
    "from sklearn.model_selection import GroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = joblib.load(f'{tmpdir}/features.joblib')\n",
    "X_trn = feather.read_dataframe(f'{tmpdir}/X_trn.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "folds = GroupKFold(n_splits=k)\n",
    "groups = X_trn['installation_id']\n",
    "X = X_trn[features].copy()\n",
    "y = X_trn['accuracy_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionCappa:\n",
    "    def __init__(self, bounds):\n",
    "        self.bounds = bounds\n",
    "    def lightgbm(self, y_true, y_pred):\n",
    "        y_rounded = round_regressor_predictions(y_pred, self.bounds)\n",
    "        return 'cappa', qwk(y_true, y_rounded), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_regressor_predictions(preds, coefs):\n",
    "    x = preds.copy()\n",
    "    for i, (lo, hi) in enumerate(zip(coefs[:-1], coefs[1:])):\n",
    "        x[(x > lo) & (x <= hi)] = i\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_metric = RegressionCappa([-np.inf, 1., 2., 3., +np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "oof = np.zeros(X.shape[0], dtype=np.float32)\n",
    "for i, (trn_idx, val_idx) in enumerate(folds.split(X, y, groups), 1):\n",
    "    print(f'Running k-fold {i} of {k}')\n",
    "    x_trn, y_trn = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    x_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    model = lgb.LGBMRegressor(n_estimators=1000, \n",
    "                              max_depth=15,\n",
    "                              metric='rmse',\n",
    "                              objective='regression',\n",
    "                              learning_rate=1e-2)\n",
    "    model.fit(x_trn, y_trn,\n",
    "              eval_set=[(x_trn, y_trn), (x_val, y_val)],\n",
    "              eval_names=['trn', 'val'],\n",
    "              eval_metric=reg_metric.lightgbm,\n",
    "              early_stopping_rounds=100,\n",
    "              verbose=50,\n",
    "              categorical_feature='auto')\n",
    "    oof[val_idx] = model.predict(x_val)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_rounding_bounds(X, y):\n",
    "    def _loss(coef):\n",
    "        buckets = pd.cut(X, [-np.inf] + list(np.sort(coef)) + [np.inf], labels=[0, 1, 2, 3])\n",
    "        return -qwk(y, buckets)\n",
    "    \n",
    "    init_coef = [0.5, 1.5, 2.5]\n",
    "    opt_coef = scipy.optimize.minimize(_loss, init_coef, method='nelder-mead')\n",
    "    optimized = opt_coef['x']\n",
    "    return [-np.inf] + optimized.tolist() + [np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_bounds = optimize_rounding_bounds(oof, y)\n",
    "opt_reg_metric = RegressionCappa(opt_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(opt_bounds, '/home/ck/data/bowl2019/external/bounds.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "oof = np.zeros(X.shape[0], dtype=np.float32)\n",
    "for i, (trn_idx, val_idx) in enumerate(folds.split(X, y, groups), 1):\n",
    "    print(f'Running k-fold {i} of {k}')\n",
    "    x_trn, y_trn = X.iloc[trn_idx], y.iloc[trn_idx]\n",
    "    x_val, y_val = X.iloc[val_idx], y.iloc[val_idx]\n",
    "    model = lgb.LGBMRegressor(n_estimators=1000, \n",
    "                              max_depth=15,\n",
    "                              metric='rmse',\n",
    "                              objective='regression',\n",
    "                              learning_rate=1e-2)\n",
    "    model.fit(x_trn, y_trn,\n",
    "              eval_set=[(x_trn, y_trn), (x_val, y_val)],\n",
    "              eval_names=['trn', 'val'],\n",
    "              eval_metric=opt_reg_metric.lightgbm,\n",
    "              early_stopping_rounds=100,\n",
    "              verbose=50,\n",
    "              categorical_feature='auto')\n",
    "    oof[val_idx] = model.predict(x_val)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(models, f'{tmpdir}/models_lightgbm_004.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as U\n",
    "from basedir import TRAIN, TEST\n",
    "from dataset import load, load_sample, Subset, to_accuracy_group\n",
    "from metric import qwk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dir = '/home/ck/data/bowl2019/external'\n",
    "!cp /tmp/bowl2019/features.joblib {export_dir}\n",
    "!cp /tmp/bowl2019/models.joblib {export_dir}\n",
    "!cp /tmp/bowl2019/meta.joblib {export_dir}\n",
    "!cp /tmp/bowl2019/train_enc.joblib {export_dir}\n",
    "!cp ../basedir.py {export_dir}\n",
    "!cp ../dataset.py {export_dir}\n",
    "!cp ../metric.py {export_dir}\n",
    "!cp ../utils.py {export_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai (cuda 10)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
